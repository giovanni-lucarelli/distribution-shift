\chapter{Conclusions}

In this work we explored how covariate shift leads to performance degradation in the roc-auc performance in a variety of models. We defined an original procedure in order to generate syntetic datasets with peculiar properties, \textit{i.e.}, multinormality of the features, second-order polinomial relationship with random coefficients. This properties togheter with random covariance matrices generation, allowed us to have a controlled and continuos way to simulate covariate shifts. In this framework, we trained several ensemble models and evaluated their performances against a logistic classifier baseline. We found ways to efficiently parallelize the workload of tuning the ensemble models and generating data. Nontheless what the analysis shows is that the degree of degradation is equal in the more complex models -- as they all perform similiarly-- while the logistic classifier served as a good baseline. Interestingly, in some instances of the problem, the latter performed as well as the ensemble models; we think this result is due to the logistic classifier's higher variance. While our analysis addressed the primary question of determining the best model to handle distribution shifts among the evaluated options, we found no substantial differences in performance. This raises a subsequent question: \textit{Why do all models behave so similarly in this context?} Our hypothesis is that the dataset was never complex enough to really challenge the models: we had to limit the features number to 3 because of compute constraints, moreover the quadratic relationship was not enough to make the problem hard. For this particular problem definition, all the models are able to achive an {upperbound} that is intrinsic to the problem nature itself. 

Our original goal was to develop an algorithm that, differing from the literature we read, didn't have any prior knowledge on the shift, \textit{i.e.}, on the testing datasets. At the core of this problem lays the fact that no data augmentation can be relevant enough when its not reflecting the nature of the real shift. The R.A.W. algorithm quickly became yet another way to assess the difficulty of performing well in a covariate shift scenario. Unfortunately, it didn't led to significant results but we still believe that not relying on any estimation on the testing set is a novel and still to be walked path.

While we do not propose specific directions for future work, our findings raise several important questions that merit further investigation. For instance, what insights might be gained by applying these methods to real-world datasets instead of synthetic ones? Additionally, is it possible to refine and enhance the R.A.W. algorithm to achieve better results, and if so, what approaches might be most effective? Addressing these questions could lead to meaningful advancements in understanding and mitigating the challenges posed by covariate shift.
