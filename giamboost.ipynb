{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, accuracy_score, \n",
    "    f1_score, roc_curve\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from pygam import s, te, f, LogisticGAM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from src.data_generation import *\n",
    "from src.analysis import ModelEvaluator\n",
    "from src.utils import *\n",
    "from src.plotting import visualize_feature_shifts\n",
    "\n",
    "from src.robust_training.mechanistic import MechanisticTrainer\n",
    "from src.robust_training.mechanistic import run_mechanistic_robust_training_and_eval_in_memory\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "GRID_SEARCH = False\n",
    "PLOT = False\n",
    "GEN_DATA = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "def evaluate_model(model, df_dict: Dict[float, pd.DataFrame], target: str) -> float:\n",
    "    \"\"\"Calculate mean AUC across all shift levels\"\"\"\n",
    "    aucs = []\n",
    "    for _, df in df_dict.items():\n",
    "        X_test = df.drop(columns=[target])\n",
    "        y_test = df[target]\n",
    "        try:\n",
    "            y_proba = model.predict_proba(X_test)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_proba)\n",
    "            aucs.append(auc)\n",
    "        except:\n",
    "            continue\n",
    "    return np.mean(aucs)\n",
    "\n",
    "def grid_search_parameters(\n",
    "    df_train: pd.DataFrame,\n",
    "    df_dict: Dict[float, pd.DataFrame],\n",
    "    target: str = 'Y',\n",
    "    shift_factors: list = [0.001, 0.01, 0.1],\n",
    "    fractions: list = [0.3, 0.5, 0.7, 0.9],\n",
    "    model_types: list = ['tree', 'gbc', 'rfc'],\n",
    "    random_state: int = 42,\n",
    "    **kwargs\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Grid search over:\n",
    "      - base_shift_factor in `shift_factors`\n",
    "      - fraction_to_shift in `fractions`\n",
    "      - model_type in `model_types`\n",
    "    Returns a DataFrame of all results plus best details per model.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Train across all combos\n",
    "    for model_type in model_types:\n",
    "        for shift_factor in shift_factors:\n",
    "            for fraction in fractions:\n",
    "                print(f\"\\nTesting shift_factor={shift_factor}, fraction={fraction}, model_type={model_type}\")\n",
    "                \n",
    "                baseline_model, robust_model = run_mechanistic_robust_training_and_eval_in_memory(\n",
    "                    df_train=df_train,\n",
    "                    df_dict=df_dict,\n",
    "                    target=target,\n",
    "                    base_shift_factor=shift_factor,\n",
    "                    fraction_to_shift=fraction,\n",
    "                    model_type=model_type,\n",
    "                    random_state=random_state,\n",
    "                    **kwargs\n",
    "                )\n",
    "                \n",
    "                robust_score = evaluate_model(robust_model, df_dict, target)\n",
    "                baseline_score = evaluate_model(baseline_model, df_dict, target)\n",
    "                \n",
    "                results.append({\n",
    "                    'model_type': model_type,\n",
    "                    'shift_factor': shift_factor,\n",
    "                    'fraction': fraction,\n",
    "                    'robust_score': robust_score,\n",
    "                    'baseline_score': baseline_score,\n",
    "                    'improvement': robust_score - baseline_score\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    # Find best (robust) score per model\n",
    "    best_per_model = {}\n",
    "    for mt in model_types:\n",
    "        model_subset = results_df[results_df['model_type'] == mt]\n",
    "        if not model_subset.empty:\n",
    "            # Row with the maximum robust_score for this model_type\n",
    "            best_idx = model_subset['robust_score'].idxmax()\n",
    "            best_row = model_subset.loc[best_idx]\n",
    "            best_per_model[mt] = {\n",
    "                'best_robust_score': best_row['robust_score'],\n",
    "                'best_baseline_score': best_row['baseline_score'],\n",
    "                'best_params': {\n",
    "                    'model_type': best_row['model_type'],\n",
    "                    'shift_factor': best_row['shift_factor'],\n",
    "                    'fraction': best_row['fraction']\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            # If no results for this model_type for some reason\n",
    "            best_per_model[mt] = None\n",
    "    \n",
    "    return {\n",
    "        'results_df': results_df,\n",
    "        'best_per_model': best_per_model\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================\n",
      "   Iteration 1/1\n",
      "===================================\n",
      "\n",
      "Testing shift_factor=0.01, fraction=0.99, model_type=tree\n",
      "Training set shape = (10000, 3);  Target distribution:\n",
      "Y\n",
      "1    5502\n",
      "0    4498\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training Baseline Model ===\n",
      "=> Baseline model trained.\n",
      "\n",
      "=== Training Robust Model ===\n",
      "[MechanisticTrainer] Initial fit on full dataset.\n",
      "[MechanisticTrainer] Augmentation Round 1/1\n",
      "  => Augmenting 10000 samples.\n",
      "  => Augmented pool size: 20000 samples\n",
      "  => Downsampled combined data to 10000 total samples.\n",
      "[MechanisticTrainer] Robust model training completed.\n",
      "\n",
      "=> Robust model trained.\n",
      "\n",
      "=== Evaluation on Shifted Datasets ===\n",
      "\n",
      "Shift = 0.0\n",
      "  Baseline => Accuracy: 0.792, F1: 0.796, AUC: 0.870\n",
      "  Robust   => Accuracy: 0.790, F1: 0.798, AUC: 0.866\n",
      "  Delta AUC (Robust - Baseline) = -0.0039\n",
      "\n",
      "Shift = 0.1\n",
      "  Baseline => Accuracy: 0.784, F1: 0.776, AUC: 0.854\n",
      "  Robust   => Accuracy: 0.785, F1: 0.783, AUC: 0.852\n",
      "  Delta AUC (Robust - Baseline) = -0.0021\n",
      "\n",
      "Shift = 0.2\n",
      "  Baseline => Accuracy: 0.762, F1: 0.741, AUC: 0.832\n",
      "  Robust   => Accuracy: 0.767, F1: 0.752, AUC: 0.832\n",
      "  Delta AUC (Robust - Baseline) = -0.0006\n",
      "\n",
      "Shift = 0.3\n",
      "  Baseline => Accuracy: 0.748, F1: 0.710, AUC: 0.808\n",
      "  Robust   => Accuracy: 0.751, F1: 0.718, AUC: 0.801\n",
      "  Delta AUC (Robust - Baseline) = -0.0074\n",
      "\n",
      "Shift = 0.4\n",
      "  Baseline => Accuracy: 0.734, F1: 0.672, AUC: 0.785\n",
      "  Robust   => Accuracy: 0.734, F1: 0.675, AUC: 0.778\n",
      "  Delta AUC (Robust - Baseline) = -0.0074\n",
      "\n",
      "Shift = 0.5\n",
      "  Baseline => Accuracy: 0.730, F1: 0.637, AUC: 0.772\n",
      "  Robust   => Accuracy: 0.729, F1: 0.637, AUC: 0.758\n",
      "  Delta AUC (Robust - Baseline) = -0.0140\n",
      "\n",
      "Shift = 0.6\n",
      "  Baseline => Accuracy: 0.710, F1: 0.593, AUC: 0.744\n",
      "  Robust   => Accuracy: 0.712, F1: 0.597, AUC: 0.733\n",
      "  Delta AUC (Robust - Baseline) = -0.0114\n",
      "\n",
      "Shift = 0.7\n",
      "  Baseline => Accuracy: 0.699, F1: 0.528, AUC: 0.707\n",
      "  Robust   => Accuracy: 0.701, F1: 0.529, AUC: 0.692\n",
      "  Delta AUC (Robust - Baseline) = -0.0153\n",
      "\n",
      "Shift = 0.8\n",
      "  Baseline => Accuracy: 0.685, F1: 0.475, AUC: 0.676\n",
      "  Robust   => Accuracy: 0.687, F1: 0.471, AUC: 0.660\n",
      "  Delta AUC (Robust - Baseline) = -0.0162\n",
      "\n",
      "Shift = 0.9\n",
      "  Baseline => Accuracy: 0.667, F1: 0.381, AUC: 0.638\n",
      "  Robust   => Accuracy: 0.667, F1: 0.373, AUC: 0.611\n",
      "  Delta AUC (Robust - Baseline) = -0.0265\n",
      "\n",
      "Shift = 1.0\n",
      "  Baseline => Accuracy: 0.661, F1: 0.319, AUC: 0.601\n",
      "  Robust   => Accuracy: 0.658, F1: 0.293, AUC: 0.574\n",
      "  Delta AUC (Robust - Baseline) = -0.0277\n",
      "\n",
      "Testing shift_factor=0.05, fraction=0.99, model_type=tree\n",
      "Training set shape = (10000, 3);  Target distribution:\n",
      "Y\n",
      "1    5502\n",
      "0    4498\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training Baseline Model ===\n",
      "=> Baseline model trained.\n",
      "\n",
      "=== Training Robust Model ===\n",
      "[MechanisticTrainer] Initial fit on full dataset.\n",
      "[MechanisticTrainer] Augmentation Round 1/1\n",
      "  => Augmenting 10000 samples.\n",
      "  => Augmented pool size: 20000 samples\n",
      "  => Downsampled combined data to 10000 total samples.\n",
      "[MechanisticTrainer] Robust model training completed.\n",
      "\n",
      "=> Robust model trained.\n",
      "\n",
      "=== Evaluation on Shifted Datasets ===\n",
      "\n",
      "Shift = 0.0\n",
      "  Baseline => Accuracy: 0.792, F1: 0.796, AUC: 0.870\n",
      "  Robust   => Accuracy: 0.788, F1: 0.798, AUC: 0.867\n",
      "  Delta AUC (Robust - Baseline) = -0.0033\n",
      "\n",
      "Shift = 0.1\n",
      "  Baseline => Accuracy: 0.784, F1: 0.776, AUC: 0.854\n",
      "  Robust   => Accuracy: 0.779, F1: 0.785, AUC: 0.855\n",
      "  Delta AUC (Robust - Baseline) = 0.0011\n",
      "\n",
      "Shift = 0.2\n",
      "  Baseline => Accuracy: 0.762, F1: 0.741, AUC: 0.832\n",
      "  Robust   => Accuracy: 0.760, F1: 0.761, AUC: 0.837\n",
      "  Delta AUC (Robust - Baseline) = 0.0042\n",
      "\n",
      "Shift = 0.3\n",
      "  Baseline => Accuracy: 0.748, F1: 0.710, AUC: 0.808\n",
      "  Robust   => Accuracy: 0.739, F1: 0.731, AUC: 0.811\n",
      "  Delta AUC (Robust - Baseline) = 0.0027\n",
      "\n",
      "Shift = 0.4\n",
      "  Baseline => Accuracy: 0.734, F1: 0.672, AUC: 0.785\n",
      "  Robust   => Accuracy: 0.711, F1: 0.691, AUC: 0.787\n",
      "  Delta AUC (Robust - Baseline) = 0.0020\n",
      "\n",
      "Shift = 0.5\n",
      "  Baseline => Accuracy: 0.730, F1: 0.637, AUC: 0.772\n",
      "  Robust   => Accuracy: 0.702, F1: 0.664, AUC: 0.777\n",
      "  Delta AUC (Robust - Baseline) = 0.0050\n",
      "\n",
      "Shift = 0.6\n",
      "  Baseline => Accuracy: 0.710, F1: 0.593, AUC: 0.744\n",
      "  Robust   => Accuracy: 0.687, F1: 0.641, AUC: 0.750\n",
      "  Delta AUC (Robust - Baseline) = 0.0055\n",
      "\n",
      "Shift = 0.7\n",
      "  Baseline => Accuracy: 0.699, F1: 0.528, AUC: 0.707\n",
      "  Robust   => Accuracy: 0.666, F1: 0.598, AUC: 0.725\n",
      "  Delta AUC (Robust - Baseline) = 0.0173\n",
      "\n",
      "Shift = 0.8\n",
      "  Baseline => Accuracy: 0.685, F1: 0.475, AUC: 0.676\n",
      "  Robust   => Accuracy: 0.651, F1: 0.571, AUC: 0.697\n",
      "  Delta AUC (Robust - Baseline) = 0.0209\n",
      "\n",
      "Shift = 0.9\n",
      "  Baseline => Accuracy: 0.667, F1: 0.381, AUC: 0.638\n",
      "  Robust   => Accuracy: 0.636, F1: 0.528, AUC: 0.665\n",
      "  Delta AUC (Robust - Baseline) = 0.0275\n",
      "\n",
      "Shift = 1.0\n",
      "  Baseline => Accuracy: 0.661, F1: 0.319, AUC: 0.601\n",
      "  Robust   => Accuracy: 0.620, F1: 0.496, AUC: 0.637\n",
      "  Delta AUC (Robust - Baseline) = 0.0353\n",
      "\n",
      "Testing shift_factor=0.01, fraction=0.99, model_type=gbc\n",
      "Training set shape = (10000, 3);  Target distribution:\n",
      "Y\n",
      "1    5502\n",
      "0    4498\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training Baseline Model ===\n",
      "=> Baseline model trained.\n",
      "\n",
      "=== Training Robust Model ===\n",
      "[MechanisticTrainer] Initial fit on full dataset.\n",
      "[MechanisticTrainer] Augmentation Round 1/1\n",
      "  => Augmenting 10000 samples.\n",
      "  => Augmented pool size: 20000 samples\n",
      "  => Downsampled combined data to 10000 total samples.\n",
      "[MechanisticTrainer] Robust model training completed.\n",
      "\n",
      "=> Robust model trained.\n",
      "\n",
      "=== Evaluation on Shifted Datasets ===\n",
      "\n",
      "Shift = 0.0\n",
      "  Baseline => Accuracy: 0.791, F1: 0.800, AUC: 0.874\n",
      "  Robust   => Accuracy: 0.789, F1: 0.798, AUC: 0.873\n",
      "  Delta AUC (Robust - Baseline) = -0.0007\n",
      "\n",
      "Shift = 0.1\n",
      "  Baseline => Accuracy: 0.785, F1: 0.783, AUC: 0.862\n",
      "  Robust   => Accuracy: 0.784, F1: 0.783, AUC: 0.862\n",
      "  Delta AUC (Robust - Baseline) = -0.0007\n",
      "\n",
      "Shift = 0.2\n",
      "  Baseline => Accuracy: 0.772, F1: 0.758, AUC: 0.849\n",
      "  Robust   => Accuracy: 0.770, F1: 0.758, AUC: 0.847\n",
      "  Delta AUC (Robust - Baseline) = -0.0018\n",
      "\n",
      "Shift = 0.3\n",
      "  Baseline => Accuracy: 0.755, F1: 0.728, AUC: 0.826\n",
      "  Robust   => Accuracy: 0.753, F1: 0.725, AUC: 0.822\n",
      "  Delta AUC (Robust - Baseline) = -0.0043\n",
      "\n",
      "Shift = 0.4\n",
      "  Baseline => Accuracy: 0.739, F1: 0.688, AUC: 0.809\n",
      "  Robust   => Accuracy: 0.735, F1: 0.686, AUC: 0.804\n",
      "  Delta AUC (Robust - Baseline) = -0.0044\n",
      "\n",
      "Shift = 0.5\n",
      "  Baseline => Accuracy: 0.735, F1: 0.657, AUC: 0.795\n",
      "  Robust   => Accuracy: 0.731, F1: 0.653, AUC: 0.790\n",
      "  Delta AUC (Robust - Baseline) = -0.0048\n",
      "\n",
      "Shift = 0.6\n",
      "  Baseline => Accuracy: 0.724, F1: 0.625, AUC: 0.773\n",
      "  Robust   => Accuracy: 0.719, F1: 0.621, AUC: 0.766\n",
      "  Delta AUC (Robust - Baseline) = -0.0069\n",
      "\n",
      "Shift = 0.7\n",
      "  Baseline => Accuracy: 0.709, F1: 0.569, AUC: 0.743\n",
      "  Robust   => Accuracy: 0.707, F1: 0.571, AUC: 0.737\n",
      "  Delta AUC (Robust - Baseline) = -0.0064\n",
      "\n",
      "Shift = 0.8\n",
      "  Baseline => Accuracy: 0.698, F1: 0.521, AUC: 0.725\n",
      "  Robust   => Accuracy: 0.693, F1: 0.524, AUC: 0.717\n",
      "  Delta AUC (Robust - Baseline) = -0.0082\n",
      "\n",
      "Shift = 0.9\n",
      "  Baseline => Accuracy: 0.682, F1: 0.443, AUC: 0.684\n",
      "  Robust   => Accuracy: 0.679, F1: 0.455, AUC: 0.679\n",
      "  Delta AUC (Robust - Baseline) = -0.0054\n",
      "\n",
      "Shift = 1.0\n",
      "  Baseline => Accuracy: 0.673, F1: 0.388, AUC: 0.661\n",
      "  Robust   => Accuracy: 0.673, F1: 0.397, AUC: 0.653\n",
      "  Delta AUC (Robust - Baseline) = -0.0078\n",
      "\n",
      "Testing shift_factor=0.05, fraction=0.99, model_type=gbc\n",
      "Training set shape = (10000, 3);  Target distribution:\n",
      "Y\n",
      "1    5502\n",
      "0    4498\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Training Baseline Model ===\n",
      "=> Baseline model trained.\n",
      "\n",
      "=== Training Robust Model ===\n",
      "[MechanisticTrainer] Initial fit on full dataset.\n",
      "[MechanisticTrainer] Augmentation Round 1/1\n",
      "  => Augmenting 10000 samples.\n",
      "  => Augmented pool size: 20000 samples\n",
      "  => Downsampled combined data to 10000 total samples.\n",
      "[MechanisticTrainer] Robust model training completed.\n",
      "\n",
      "=> Robust model trained.\n",
      "\n",
      "=== Evaluation on Shifted Datasets ===\n",
      "\n",
      "Shift = 0.0\n",
      "  Baseline => Accuracy: 0.791, F1: 0.800, AUC: 0.874\n",
      "  Robust   => Accuracy: 0.793, F1: 0.802, AUC: 0.873\n",
      "  Delta AUC (Robust - Baseline) = -0.0010\n",
      "\n",
      "Shift = 0.1\n",
      "  Baseline => Accuracy: 0.785, F1: 0.783, AUC: 0.862\n",
      "  Robust   => Accuracy: 0.784, F1: 0.782, AUC: 0.863\n",
      "  Delta AUC (Robust - Baseline) = 0.0008\n",
      "\n",
      "Shift = 0.2\n",
      "  Baseline => Accuracy: 0.772, F1: 0.758, AUC: 0.849\n",
      "  Robust   => Accuracy: 0.771, F1: 0.757, AUC: 0.848\n",
      "  Delta AUC (Robust - Baseline) = -0.0007\n",
      "\n",
      "Shift = 0.3\n",
      "  Baseline => Accuracy: 0.755, F1: 0.728, AUC: 0.826\n",
      "  Robust   => Accuracy: 0.756, F1: 0.726, AUC: 0.827\n",
      "  Delta AUC (Robust - Baseline) = 0.0007\n",
      "\n",
      "Shift = 0.4\n",
      "  Baseline => Accuracy: 0.739, F1: 0.688, AUC: 0.809\n",
      "  Robust   => Accuracy: 0.737, F1: 0.681, AUC: 0.808\n",
      "  Delta AUC (Robust - Baseline) = -0.0009\n",
      "\n",
      "Shift = 0.5\n",
      "  Baseline => Accuracy: 0.735, F1: 0.657, AUC: 0.795\n",
      "  Robust   => Accuracy: 0.736, F1: 0.651, AUC: 0.796\n",
      "  Delta AUC (Robust - Baseline) = 0.0016\n",
      "\n",
      "Shift = 0.6\n",
      "  Baseline => Accuracy: 0.724, F1: 0.625, AUC: 0.773\n",
      "  Robust   => Accuracy: 0.727, F1: 0.623, AUC: 0.775\n",
      "  Delta AUC (Robust - Baseline) = 0.0029\n",
      "\n",
      "Shift = 0.7\n",
      "  Baseline => Accuracy: 0.709, F1: 0.569, AUC: 0.743\n",
      "  Robust   => Accuracy: 0.706, F1: 0.551, AUC: 0.746\n",
      "  Delta AUC (Robust - Baseline) = 0.0031\n",
      "\n",
      "Shift = 0.8\n",
      "  Baseline => Accuracy: 0.698, F1: 0.521, AUC: 0.725\n",
      "  Robust   => Accuracy: 0.699, F1: 0.505, AUC: 0.729\n",
      "  Delta AUC (Robust - Baseline) = 0.0034\n",
      "\n",
      "Shift = 0.9\n",
      "  Baseline => Accuracy: 0.682, F1: 0.443, AUC: 0.684\n",
      "  Robust   => Accuracy: 0.683, F1: 0.424, AUC: 0.690\n",
      "  Delta AUC (Robust - Baseline) = 0.0056\n",
      "\n",
      "Shift = 1.0\n",
      "  Baseline => Accuracy: 0.673, F1: 0.388, AUC: 0.661\n",
      "  Robust   => Accuracy: 0.677, F1: 0.356, AUC: 0.667\n",
      "  Delta AUC (Robust - Baseline) = 0.0058\n",
      "\n",
      "[Iteration 1] Best for TREE:\n",
      "  Score:       0.7642\n",
      "  Baseline:    0.7534\n",
      "  shift_factor=0.05, fraction=0.99\n",
      "\n",
      "[Iteration 1] Best for GBC:\n",
      "  Score:       0.7838\n",
      "  Baseline:    0.7819\n",
      "  shift_factor=0.05, fraction=0.99\n",
      "\n",
      "Iteration 1:\n",
      "[[ 0.9039851   0.16690915 -0.47712294]\n",
      " [ 0.16690915  0.54035022 -0.5390128 ]\n",
      " [-0.47712294 -0.5390128   1.61493558]]\n",
      "\n",
      "Finished all iterations.\n",
      "\n",
      "========== Iteration 1 best results per model ===========\n",
      "  TREE: best_robust_score=0.7642, best_baseline_score=0.7534, params={'model_type': 'tree', 'shift_factor': 0.05, 'fraction': 0.99}\n",
      "  GBC: best_robust_score=0.7838, best_baseline_score=0.7819, params={'model_type': 'gbc', 'shift_factor': 0.05, 'fraction': 0.99}\n",
      "-----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "N = 1  # Number of times to generate data and run the grid search\n",
    "\n",
    "# We'll store the best results for each iteration in a list of dicts:\n",
    "all_best_per_model = []\n",
    "\n",
    "# Data generation parameters\n",
    "num_samples = 10000\n",
    "num_features = 3\n",
    "degree = 2  # degree for polynomial\n",
    "all_covariance_shifts = [] \n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Generate TRAIN data once (outside the loop)\n",
    "# ------------------------------------------------------------\n",
    "if GEN_DATA:\n",
    "    mean_train = [0.90920214, 0.81962487, 0.88819135]\n",
    "    covariance_train = np.array([\n",
    "        [0.726318,     0.20240102,  0.52472545],\n",
    "        [0.20240102,   0.11392557,  0.0264108],\n",
    "        [0.52472545,   0.0264108,   1.05107627]\n",
    "    ])\n",
    "    \n",
    "    sample_train = build_multivariate_sample(num_samples, mean_train, covariance_train)\n",
    "    df_train = pd.DataFrame(sample_train, columns=[f'X{i+1}' for i in range(num_features)])\n",
    "    \n",
    "    # Polinomial coefficients for target generation\n",
    "    coef = [\n",
    "        -0.8061577012389105, -0.3621987584904036, -0.16057091147074054, \n",
    "         0.4803476403769713, -0.10624889645240687,  0.3182084398201366, \n",
    "         0.6789895126695962, -0.791324832566177,    0.531479159887424, \n",
    "         0.49115959567000167\n",
    "    ]\n",
    "    y_train,  coef_train = build_poly_target(sample_train, degree, coef)\n",
    "    df_train['Y'] = y_train\n",
    "    \n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main loop - run N times\n",
    "# ------------------------------------------------------------\n",
    "for iteration in range(N):\n",
    "    print(f\"\\n{'='*35}\")\n",
    "    print(f\"   Iteration {iteration+1}/{N}\")\n",
    "    print(f\"{'='*35}\")\n",
    "    \n",
    "    # --------------------------------------------------------\n",
    "    # Generate SHIFTED TEST data in each iteration (optional)\n",
    "    # --------------------------------------------------------\n",
    "    if GEN_DATA:\n",
    "        mean_shift = attributes_quantile(df_train, 0.05)\n",
    "        covariance_shift = random_cov(num_features)\n",
    "        all_covariance_shifts.append(covariance_shift)\n",
    "        \n",
    "        df_dict = {}\n",
    "        for mix_prob in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, \n",
    "                         0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "            sample_mix = build_mixture_sample(\n",
    "                num_samples, \n",
    "                mean_train, covariance_train, \n",
    "                mean_shift, covariance_shift, \n",
    "                mix_prob=mix_prob\n",
    "            )\n",
    "            df_mix = pd.DataFrame(sample_mix, columns=[f'X{i+1}' for i in range(num_features)])\n",
    "            y_mix,  _ = build_poly_target(sample_mix, degree, coefficients=coef_train)\n",
    "            df_mix['Y'] = y_mix\n",
    "            \n",
    "            df_dict[mix_prob] = df_mix\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # Grid search: specify the models and parameters to test\n",
    "    # --------------------------------------------------------\n",
    "    grid_results = grid_search_parameters(\n",
    "        df_train=df_train,\n",
    "        df_dict=df_dict,\n",
    "        target='Y',\n",
    "        shift_factors=[0.01, 0.05], \n",
    "        fractions=[ 0.99],\n",
    "        model_types=['tree','gbc'],  \n",
    "        n_rounds=1,\n",
    "        random_state=42,\n",
    "        noise_scale=0.0\n",
    "    )\n",
    "    \n",
    "    # Extract the best result for each model\n",
    "    best_per_model = grid_results['best_per_model']\n",
    "    all_best_per_model.append(best_per_model)\n",
    "    \n",
    "    # Print a summary for this iteration\n",
    "    for model_type, info in best_per_model.items():\n",
    "        if info is not None:\n",
    "            print(f\"\\n[Iteration {iteration+1}] Best for {model_type.upper()}:\")\n",
    "            print(f\"  Score:       {info['best_robust_score']:.4f}\")\n",
    "            print(f\"  Baseline:    {info['best_baseline_score']:.4f}\")\n",
    "            print(f\"  shift_factor={info['best_params']['shift_factor']}, fraction={info['best_params']['fraction']}\")\n",
    "        else:\n",
    "            print(f\"[Iteration {iteration+1}] No result found for model_type={model_type}.\")\n",
    "    for i, cov in enumerate(all_covariance_shifts):\n",
    "        print(f\"\\nIteration {i+1}:\")\n",
    "        print(cov)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# After finishing all iterations\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nFinished all iterations.\\n\")\n",
    "for i, best_dict in enumerate(all_best_per_model, start=1):\n",
    "    print(f\"========== Iteration {i} best results per model ===========\")\n",
    "    for model_type, info in best_dict.items():\n",
    "        if info is not None:\n",
    "            print(f\"  {model_type.upper()}: best_robust_score={info['best_robust_score']:.4f}, \"\n",
    "                  f\"best_baseline_score={info['best_baseline_score']:.4f}, \"\n",
    "                  f\"Robust Train params={info['best_params']}\")\n",
    "        else:\n",
    "            print(f\"  {model_type.upper()}: No result.\")\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
