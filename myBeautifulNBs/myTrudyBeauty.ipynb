{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, accuracy_score, \n",
    "    f1_score, roc_curve\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the sigmoid activation function element-wise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Input array.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Sigmoid output, same shape as input.\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def generate_synthetic_dataset(\n",
    "    n_features: int = 4,\n",
    "    pi: float = 0.5,\n",
    "    cov_scale: float = 3.5,\n",
    "    mean_shift_scale: float = 1.5,\n",
    "    n_samples: int = 1000,\n",
    "    random_seed: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a synthetic dataset by mixing two n_features-dimensional\n",
    "    Gaussian distributions:\n",
    "      - distribution A with (mean0, cov0)\n",
    "      - distribution B with (mean1, cov1)\n",
    "\n",
    "    Mixture controlled by 'pi': fraction from distribution B vs. A.\n",
    "\n",
    "    A label is generated by applying a random linear transformation followed by \n",
    "    a logistic (sigmoid) function: y = Bernoulli(sigmoid(X @ w)).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_features : int, optional\n",
    "        Dimensionality of the feature space, by default 3.\n",
    "    pi : float, optional\n",
    "        Probability of drawing from distribution B (vs A), by default 0.5.\n",
    "    cov_scale : float, optional\n",
    "        Scaling factor for the second distribution's covariance, by default 3.5.\n",
    "    mean_shift_scale : float, optional\n",
    "        Scaling factor for the second distribution's mean, by default 1.5.\n",
    "    n_samples : int, optional\n",
    "        Number of samples to generate, by default 1000.\n",
    "    random_seed : int, optional\n",
    "        Seed for reproducibility, by default 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (X, y) : (np.ndarray, np.ndarray)\n",
    "        - X is of shape (n_samples, n_features)\n",
    "        - y is of shape (n_samples,)\n",
    "    \"\"\"\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "   \n",
    "    A = np.random.rand(n_features, n_features) * 10\n",
    "    cov0 = A @ A.T  \n",
    "    mean0 = np.random.uniform(5, 15, size=n_features)\n",
    "\n",
    "    # Orthogonal transform for distribution B (shifted)\n",
    "    random_ortho = ortho_group.rvs(dim=n_features)\n",
    "    cov1 = random_ortho @ cov0 @ random_ortho.T\n",
    "    cov1 *= cov_scale\n",
    "    mean1 = mean0 * mean_shift_scale\n",
    "\n",
    "    # Mixture selection. THE HIGHER PI THE MORE LIKELY TO DRAW FROM SHIFTED DISTRIBUTION  \n",
    "    choices = np.random.choice([0, 1], size=n_samples, p=[1 - pi, pi])\n",
    "    X = np.zeros((n_samples, n_features))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        if choices[i] == 0:\n",
    "            X[i] = np.random.multivariate_normal(mean0, cov0)\n",
    "        else:\n",
    "            X[i] = np.random.multivariate_normal(mean1, cov1)\n",
    "\n",
    "    \n",
    "    weights = np.random.uniform(-0.5, 0.5, size=n_features)  # Generate random weights for label generation\n",
    "    z = X @ weights\n",
    "    probs = sigmoid(z)\n",
    "    y = np.random.binomial(1, probs)\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2. Creating and Storing Shifted Datasets (Flexible n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_shifted_datasets(\n",
    "    n_features: int = 2, \n",
    "    output_folder: str = \"generated_data\",\n",
    "    base_n_samples: int = 1000,\n",
    "    cov_scale: float = 3.5,\n",
    "    mean_shift_scale: float = 1.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates multiple CSVs in `output_folder` for different pi values. \n",
    "    Each CSV contains [feature_0, ..., feature_{n_features-1}, target].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_features : int, optional\n",
    "        Dimensionality of generated data, by default 2.\n",
    "    output_folder : str, optional\n",
    "        Where to store generated CSVs, by default \"generated_data\".\n",
    "    base_n_samples : int, optional\n",
    "        Number of samples for each dataset, by default 1000.\n",
    "    cov_scale : float, optional\n",
    "        Scaling factor for the shifted distribution's covariance, by default 3.5.\n",
    "    mean_shift_scale : float, optional\n",
    "        Scaling factor for the shifted distribution's mean, by default 1.5.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    X_orig, y_orig = generate_synthetic_dataset(            # \"original\" data: fix pi=0 => everything from distribution A (no shift)\n",
    "        n_features=n_features,\n",
    "        pi=0.0, \n",
    "        cov_scale=1.0, \n",
    "        mean_shift_scale=1.0, \n",
    "        n_samples=base_n_samples\n",
    "    )\n",
    "    columns = [f'feature_{i}' for i in range(n_features)]\n",
    "    df_orig = pd.DataFrame(X_orig, columns=columns)\n",
    "    df_orig['target'] = y_orig\n",
    "    df_orig.to_csv(os.path.join(output_folder, 'original.csv'), index=False)\n",
    "    \n",
    "    \n",
    "    pi_values = [0.1,0.3, 0.5, 0.7, 0.9]\n",
    "    for pi in pi_values:                                # Creating multiple \"shifted\" versions with different pi\n",
    "        X_shift, y_shift = generate_synthetic_dataset(\n",
    "            n_features=n_features,\n",
    "            pi=pi, \n",
    "            cov_scale=cov_scale, \n",
    "            mean_shift_scale=mean_shift_scale, \n",
    "            n_samples=base_n_samples\n",
    "        )\n",
    "        df_shift = pd.DataFrame(X_shift, columns=columns)\n",
    "        df_shift['target'] = y_shift\n",
    "        df_shift.to_csv(os.path.join(output_folder, f'shifted_{pi}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Example: Create 2D shift data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_shifted_datasets(n_features=4, output_folder=\"data_folder\", base_n_samples=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 3. Visualization for n-Dimensional Data\n",
    "\n",
    "\n",
    "\n",
    " For higher dimensional data (n > 2), we can either:\n",
    "\n",
    " - Visualize a pairwise scatter matrix (e.g., `sns.pairplot`) for a subset of features.\n",
    "\n",
    " - Or just visualize a specified pair of features for a quick glimpse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_feature_shifts(\n",
    "    folder: str = \"data_folder\",\n",
    "    features_to_plot: tuple = (0, 1)\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots distributions for 'original.csv' vs. each 'shifted_*.csv' file.\n",
    "    Because data can be high-dimensional, we only plot two chosen dimensions \n",
    "    for scatter. For histograms, we also only plot these two selected features.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : str, optional\n",
    "        The folder containing 'original.csv' and 'shifted_*.csv'.\n",
    "    features_to_plot : tuple, optional\n",
    "        Which two feature indices to visualize in scatter/hist, by default (0,1).\n",
    "    \"\"\"\n",
    "    files = [f for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "    original_file = [f for f in files if \"original.csv\" in f]\n",
    "    \n",
    "    if len(original_file) == 0:\n",
    "        print(\"No original.csv found!\")\n",
    "        return\n",
    "    \n",
    "    # Load original\n",
    "    df_orig = pd.read_csv(os.path.join(folder, original_file[0]))\n",
    "    feat0, feat1 = features_to_plot\n",
    "    col0, col1 = f\"feature_{feat0}\", f\"feature_{feat1}\"\n",
    "    \n",
    "    # Identify shifted files\n",
    "    shifted_files = [f for f in files if \"shifted_\" in f]\n",
    "    \n",
    "    # 1) 2D Scatter \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(\n",
    "        df_orig[col0], df_orig[col1],\n",
    "        alpha=0.3, label='Original'\n",
    "    )\n",
    "    \n",
    "    for sf in shifted_files:\n",
    "        df_s = pd.read_csv(os.path.join(folder, sf))\n",
    "        plt.scatter(\n",
    "            df_s[col0], df_s[col1],\n",
    "            alpha=0.3, label=sf\n",
    "        )\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.title(f\"Scatterplot: Original vs. Shifted [Features {feat0} & {feat1}]\")\n",
    "    plt.xlabel(col0)\n",
    "    plt.ylabel(col1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    for sf in shifted_files:\n",
    "        df_s = pd.read_csv(os.path.join(folder, sf))\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 4), sharey=True)        # 2) Histograms for these 2 features\n",
    "        \n",
    "        sns.histplot(\n",
    "            df_orig[col0], color=\"blue\", alpha=0.4, ax=axes[0], \n",
    "            label='Orig '+col0, kde=True\n",
    "        )\n",
    "        sns.histplot(\n",
    "            df_s[col0], color=\"red\", alpha=0.4, ax=axes[0], \n",
    "            label=sf+\" \"+col0, kde=True\n",
    "        )\n",
    "        axes[0].set_title(f\"Distribution of {col0}\")\n",
    "        axes[0].legend()\n",
    "        \n",
    "        sns.histplot(\n",
    "            df_orig[col1], color=\"blue\", alpha=0.4, ax=axes[1], \n",
    "            label='Orig '+col1, kde=True\n",
    "        )\n",
    "        sns.histplot(\n",
    "            df_s[col1], color=\"red\", alpha=0.4, ax=axes[1], \n",
    "            label=sf+\" \"+col1, kde=True\n",
    "        )\n",
    "        axes[1].set_title(f\"Distribution of {col1}\")\n",
    "        axes[1].legend()\n",
    "        \n",
    "        plt.suptitle(f\"Feature Distributions Comparison: {sf}\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Example Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_feature_shifts(\"data_folder\", features_to_plot=(2,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 4. Baseline Model Evaluation Across Shifts (General n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: search for the best hyperparameters for the models\n",
    "\n",
    "\n",
    "def evaluate_models_on_shifts(folder: str = \"data_folder\"): \n",
    "    \"\"\"\n",
    "    1) Train a DecisionTree and a GradientBoosting model on 'original.csv'.\n",
    "    2) Evaluate each model on all 'shifted_*' CSVs in the folder.\n",
    "    3) Print metrics (Accuracy, F1, AUC) and plot ROC curves.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : str, optional\n",
    "        Folder containing 'original.csv' and 'shifted_*.csv'.\n",
    "    \"\"\"\n",
    "    # Load original => train data\n",
    "    df_orig = pd.read_csv(os.path.join(folder, \"original.csv\"))\n",
    "    X_train = df_orig.drop('target', axis=1)\n",
    "    y_train = df_orig['target']\n",
    "    \n",
    "    # Fit Decision Tree\n",
    "    dtc = DecisionTreeClassifier(max_depth=4, min_samples_leaf=13)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    \n",
    "    # Fit GradientBoosting\n",
    "    gbc = GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        max_features='log2',\n",
    "        min_samples_leaf=13,\n",
    "        n_estimators=100,\n",
    "        subsample=0.7\n",
    "    )\n",
    "    gbc.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on shifted sets\n",
    "    test_files = [f for f in os.listdir(folder) if f.startswith(\"shifted_\")]\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    color_map = {\"DecisionTree\": \"blue\", \"GradientBoosting\": \"red\"}\n",
    "    \n",
    "    for model, name in zip([dtc, gbc], [\"DecisionTree\", \"GradientBoosting\"]):\n",
    "        color = color_map[name]\n",
    "        for test_file in test_files:\n",
    "            df_test = pd.read_csv(os.path.join(folder, test_file))\n",
    "            X_test = df_test.drop('target', axis=1)\n",
    "            y_test = df_test['target']\n",
    "            \n",
    "            y_pred = model.predict(X_test)\n",
    "            y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1_ = f1_score(y_test, y_pred)\n",
    "            auc_ = roc_auc_score(y_test, y_pred_proba)\n",
    "            \n",
    "            print(f\"=== {name} on {test_file} ===\")\n",
    "            print(f\"Accuracy: {acc:.3f}, F1: {f1_:.3f}, AUC: {auc_:.3f}\")\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            print(\"---------------------------------------------------\")\n",
    "            \n",
    "            # ROC curve\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            label_str = f\"{name}-{test_file} (AUC={auc_:.3f})\"\n",
    "            plt.plot(fpr, tpr, label=label_str, color=color, alpha=0.3)\n",
    "    \n",
    "    \n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curves on Shifted Test Sets\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Example Baseline Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate_models_on_shifts(\"data_folder\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 5. Adversarial Training for GradientBoosting (General n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def generate_adversarial_samples_gbc(\n",
    "    model,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    epsilon: float = 0.1,\n",
    "    max_rounds: int = 3,\n",
    "    fraction_to_perturb: float = 0.5,\n",
    "    random_state: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Improved adversarial sample generator.\n",
    "    - We do multiple smaller steps (up to max_rounds).\n",
    "    - Each round we only perturb a subset (fraction_to_perturb) of samples\n",
    "      (e.g., those with the highest model confidence or chosen randomly).\n",
    "    - We apply a smaller shift epsilon in each round.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : fitted classifier with predict_proba\n",
    "    X : pd.DataFrame\n",
    "        Original features (n_samples, n_features).\n",
    "    y : pd.Series\n",
    "        True labels.\n",
    "    epsilon : float\n",
    "        Base step size for each round.\n",
    "    max_rounds : int\n",
    "        Number of small-shift rounds to perform.\n",
    "    fraction_to_perturb : float\n",
    "        Fraction of samples to adversarially perturb each round.\n",
    "    random_state : int\n",
    "        Random seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_adv : pd.DataFrame\n",
    "        Adversarially perturbed features, same shape as X but with partial modifications.\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    X_adv = X.copy()\n",
    "    \n",
    "    for round_idx in range(max_rounds):\n",
    "        # Possibly pick the subset of samples to perturb\n",
    "        n_samples = len(X_adv)\n",
    "        subset_size = int(fraction_to_perturb * n_samples)\n",
    "        \n",
    "        # Example strategy: pick the samples where the model is most confident\n",
    "        # OR randomly pick subset. Here we do random for simplicity:\n",
    "        indices_to_perturb = rng.choice(n_samples, size=subset_size, replace=False)\n",
    "        \n",
    "        for i in indices_to_perturb:\n",
    "            x_i = X_adv.iloc[i].values.copy()\n",
    "            true_label = y.iloc[i]\n",
    "            \n",
    "            # For each feature, do small +/- delta checks\n",
    "            for feat_idx in range(len(x_i)):\n",
    "                x_i_pos = x_i.copy()\n",
    "                x_i_neg = x_i.copy()\n",
    "                x_i_pos[feat_idx] += 1e-3\n",
    "                x_i_neg[feat_idx] -= 1e-3\n",
    "                prob_pos = model.predict_proba([x_i_pos])[0][true_label]\n",
    "                prob_neg = model.predict_proba([x_i_neg])[0][true_label]\n",
    "                \n",
    "                grad_est = (prob_pos - prob_neg) / (2e-3)\n",
    "                # Move in direction that *lowers* probability of the correct label\n",
    "                direction = -1 if grad_est > 0 else 1\n",
    "                # Smaller step\n",
    "                x_i[feat_idx] += direction * epsilon\n",
    "            \n",
    "            X_adv.iloc[i] = x_i\n",
    "            \n",
    "        # Optional: re-fit the model incrementally, or we can do a single re-fit outside\n",
    "        # For demonstration, let's do a single final re-fit outside this function.\n",
    "    \n",
    "    return X_adv\n",
    "\n",
    "\n",
    "def adversarial_training_gbc(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    base_model=None,\n",
    "    epsilon: float = 0.1,\n",
    "    max_rounds: int = 3,\n",
    "    fraction_to_perturb: float = 0.5,\n",
    "    final_train_size: int = None,\n",
    "    random_state: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    1) Fit the base_model (or default GB) on (X_train, y_train).\n",
    "    2) Generate improved adversarial samples in multiple small steps.\n",
    "    3) Augment the dataset -> (X_aug, y_aug).\n",
    "    4) Downsample to final_train_size (to ensure same #samples as baseline).\n",
    "    5) Retrain a new model on the final augmented set.\n",
    "    \"\"\"\n",
    "    if base_model is None:\n",
    "        base_model = GradientBoostingClassifier(\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            max_features='log2',\n",
    "            min_samples_leaf=13,\n",
    "            n_estimators=100,\n",
    "            subsample=0.7,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    \n",
    "    # 1) Fit the initial model\n",
    "    base_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 2) Generate adversarial samples (multiple smaller shifts)\n",
    "    X_adv = generate_adversarial_samples_gbc(\n",
    "        model=base_model,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        epsilon=epsilon,\n",
    "        max_rounds=max_rounds,\n",
    "        fraction_to_perturb=fraction_to_perturb,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    y_adv = y_train.copy()  # same labels\n",
    "    \n",
    "    # 3) Augment dataset\n",
    "    X_aug = pd.concat([X_train, X_adv], ignore_index=True)\n",
    "    y_aug = pd.concat([y_train, y_adv], ignore_index=True)\n",
    "    \n",
    "    # 4) Downsample to final_train_size if needed\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    if final_train_size is not None and final_train_size < len(X_aug):\n",
    "        indices = rng.choice(len(X_aug), size=final_train_size, replace=False)\n",
    "        X_aug = X_aug.iloc[indices].reset_index(drop=True)\n",
    "        y_aug = y_aug.iloc[indices].reset_index(drop=True)\n",
    "    \n",
    "    # 5) Retrain final model\n",
    "    adv_model = GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        max_features='log2',\n",
    "        min_samples_leaf=13,\n",
    "        n_estimators=100,\n",
    "        subsample=0.7,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    adv_model.fit(X_aug, y_aug)\n",
    "    \n",
    "    return adv_model, X_aug, y_aug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Compare Normal vs. Adversarial Training on Shifted Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_adversarial_training(folder: str = \"data_folder\"):\n",
    "    \"\"\"\n",
    "    Demonstrates the effect of adversarial training:\n",
    "      1) Train a normal GradientBoosting on original.csv.\n",
    "      2) Train an adversarially-augmented GradientBoosting on the same dataset.\n",
    "      3) Compare performance on each shifted dataset.\n",
    "    \"\"\"\n",
    "    # 1) Load original => train data\n",
    "    df_orig = pd.read_csv(os.path.join(folder, \"original.csv\"))\n",
    "    X_train = df_orig.drop('target', axis=1)\n",
    "    y_train = df_orig['target']\n",
    "    \n",
    "    # Normal GBC\n",
    "    gbc_normal = GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        max_features='log2',\n",
    "        min_samples_leaf=13,\n",
    "        n_estimators=100,\n",
    "        subsample=0.7\n",
    "    )\n",
    "    gbc_normal.fit(X_train, y_train)\n",
    "    \n",
    "    # Adversarial training\n",
    "    gbc_adversarial, X_aug, y_aug = adversarial_training_gbc(\n",
    "        X_train, y_train, \n",
    "        epsilon=0.2, \n",
    "        \n",
    "    )\n",
    "    \n",
    "    # 2) Evaluate on shifted sets\n",
    "    test_files = [f for f in os.listdir(folder) if f.startswith(\"shifted_\")]\n",
    "    \n",
    "    print(\"\\n=== Evaluate Normal GBC vs. Adversarial GBC on Shifted Data ===\\n\")\n",
    "    for test_file in test_files:\n",
    "        df_test = pd.read_csv(os.path.join(folder, test_file))\n",
    "        X_test = df_test.drop('target', axis=1)\n",
    "        y_test = df_test['target']\n",
    "        \n",
    "        # Normal\n",
    "        y_pred_n = gbc_normal.predict(X_test)\n",
    "        y_proba_n = gbc_normal.predict_proba(X_test)[:, 1]\n",
    "        acc_n = accuracy_score(y_test, y_pred_n)\n",
    "        f1_n = f1_score(y_test, y_pred_n)\n",
    "        auc_n = roc_auc_score(y_test, y_proba_n)\n",
    "        \n",
    "        # Adversarial\n",
    "        y_pred_a = gbc_adversarial.predict(X_test)\n",
    "        y_proba_a = gbc_adversarial.predict_proba(X_test)[:, 1]\n",
    "        acc_a = accuracy_score(y_test, y_pred_a)\n",
    "        f1_a = f1_score(y_test, y_pred_a)\n",
    "        auc_a = roc_auc_score(y_test, y_proba_a)\n",
    "        \n",
    "        print(f\"Shifted file: {test_file}\")\n",
    "        print(f\"  Normal GBC => Acc: {acc_n:.3f}, F1: {f1_n:.3f}, AUC: {auc_n:.3f}\")\n",
    "        print(f\"  AdvTrain GBC => Acc: {acc_a:.3f}, F1: {f1_a:.3f}, AUC: {auc_a:.3f}\")\n",
    "        print(\"---------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_adversarial_training(\"data_folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 6. Mechanistic-Interpretability-Guided Robust Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mech_interp_boosting(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    base_model=None,\n",
    "    base_shift_factor: float = 0.1,\n",
    "    n_rounds: int = 2,\n",
    "    fraction_to_shift: float = 0.3,\n",
    "    min_improvement: float = 0.001,\n",
    "    noise_scale: float = 0.01,\n",
    "    n_features_to_shift: int = 1,\n",
    "    final_train_size: int = None,\n",
    "    use_weighted_fit: bool = False,\n",
    "    random_state: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Improved Mechanistic-Interpretability-Guided Robust Boosting.\n",
    "    \n",
    "    Changes:\n",
    "      1) Per-round, only shift a fraction of samples (fraction_to_shift).\n",
    "      2) Weighted training (optional): shift data can have a higher sample_weight, \n",
    "         so the model doesn't need an even bigger dataset but still focuses on them.\n",
    "      3) Repeated smaller shift_factor, combined with early stopping on a validation set.\n",
    "      4) Final downsampling to ensure fair #samples vs. baseline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_train, y_train : pd.DataFrame, pd.Series\n",
    "        Original data\n",
    "    base_model : fitted or None\n",
    "        If None, a new GradientBoostingClassifier is created.\n",
    "    base_shift_factor : float\n",
    "        Initial magnitude of shift for the selected features.\n",
    "    n_rounds : int\n",
    "        Max number of augmentation rounds.\n",
    "    fraction_to_shift : float\n",
    "        Fraction of samples to shift each round.\n",
    "    min_improvement : float\n",
    "        Minimum improvement in validation for continuing rounds.\n",
    "    noise_scale : float\n",
    "        Std dev of random noise added to each shifted sample.\n",
    "    n_features_to_shift : int\n",
    "        # of top features to shift.\n",
    "    final_train_size : int or None\n",
    "        If not None, downsample the final augmented set to this size.\n",
    "    use_weighted_fit : bool\n",
    "        If True, we apply sample weights that are higher for newly shifted samples.\n",
    "    random_state : int\n",
    "        Reproducibility seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : GradientBoostingClassifier\n",
    "        The final robust model after all rounds.\n",
    "    X_final, y_final : final training set used to fit (with or without weighting).\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    if base_model is None:\n",
    "        base_model = GradientBoostingClassifier(\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            max_features='log2',\n",
    "            min_samples_leaf=13,\n",
    "            n_estimators=100,\n",
    "            subsample=0.7,\n",
    "            random_state=random_state\n",
    "        )\n",
    "\n",
    "    # Train/Val split\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # This is the growing augmented set\n",
    "    X_aug = X_tr.copy()\n",
    "    y_aug = y_tr.copy()\n",
    "    # (optional) Keep track of sample weights\n",
    "    sample_weights = np.ones(len(X_aug))  # default weight=1\n",
    "\n",
    "    best_val_score = 0.0\n",
    "    rounds_without_improvement = 0\n",
    "    \n",
    "    for round_idx in range(n_rounds):\n",
    "        # Fit the model with or without weighting\n",
    "        if use_weighted_fit:\n",
    "            base_model.fit(X_aug, y_aug, sample_weight=sample_weights)\n",
    "        else:\n",
    "            base_model.fit(X_aug, y_aug)\n",
    "        \n",
    "        val_score = base_model.score(X_val, y_val)\n",
    "        print(f\"[Round {round_idx+1}] Validation Score = {val_score:.3f}\")\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_score > best_val_score + min_improvement:\n",
    "            best_val_score = val_score\n",
    "            rounds_without_improvement = 0\n",
    "        else:\n",
    "            rounds_without_improvement += 1\n",
    "            if rounds_without_improvement >= 3:\n",
    "                print(f\"Early stopping at round {round_idx+1}\")\n",
    "                break\n",
    "\n",
    "        # SHIFT SAMPLES:\n",
    "        # Only shift fraction_to_shift portion of the data\n",
    "        n_current = len(X_aug)\n",
    "        subset_size = int(fraction_to_shift * n_current)\n",
    "        idx_to_shift = rng.choice(n_current, size=subset_size, replace=False)\n",
    "        \n",
    "        shift_list = []\n",
    "        label_list = []\n",
    "        weight_list = []\n",
    "\n",
    "        current_shift_factor = base_shift_factor * (0.9 ** round_idx)\n",
    "        \n",
    "        for i in idx_to_shift:\n",
    "            x_i = X_aug.iloc[i].values.copy()\n",
    "            label_i = y_aug.iloc[i]\n",
    "            \n",
    "            # Compute approximate gradient-based feature importance\n",
    "            # Probability of correct label\n",
    "            prob_original = base_model.predict_proba([x_i])[0][label_i]\n",
    "\n",
    "            feature_scores = []\n",
    "            for feat_idx in range(len(x_i)):\n",
    "                x_pos = x_i.copy()\n",
    "                x_neg = x_i.copy()\n",
    "                x_pos[feat_idx] += 1e-3\n",
    "                x_neg[feat_idx] -= 1e-3\n",
    "                prob_pos = base_model.predict_proba([x_pos])[0][label_i]\n",
    "                prob_neg = base_model.predict_proba([x_neg])[0][label_i]\n",
    "                grad_est = (prob_pos - prob_neg) / (2e-3)\n",
    "                feature_scores.append(abs(grad_est))\n",
    "            \n",
    "            top_feats = np.argsort(feature_scores)[-n_features_to_shift:]\n",
    "            \n",
    "            shift_dir = np.zeros_like(x_i)\n",
    "            for feat_idx in top_feats:\n",
    "                # Recompute sign(grad) to see which direction lowers prob\n",
    "                x_pos[feat_idx] = x_i[feat_idx] + 1e-3\n",
    "                x_neg[feat_idx] = x_i[feat_idx] - 1e-3\n",
    "                prob_pos = base_model.predict_proba([x_pos])[0][label_i]\n",
    "                prob_neg = base_model.predict_proba([x_neg])[0][label_i]\n",
    "                actual_grad = (prob_pos - prob_neg) / (2e-3)\n",
    "                direction_sign = -1 if actual_grad > 0 else 1\n",
    "                shift_dir[feat_idx] = direction_sign\n",
    "\n",
    "            noise = rng.normal(0, noise_scale, size=len(x_i))\n",
    "            x_shifted = x_i + shift_dir * current_shift_factor + noise\n",
    "            \n",
    "            shift_list.append(x_shifted)\n",
    "            label_list.append(label_i)\n",
    "            if use_weighted_fit:\n",
    "                # e.g., give a slightly higher weight, so model focuses on these new shifted points\n",
    "                weight_list.append(2.0)  # shift points weight=2.0\n",
    "            else:\n",
    "                weight_list.append(1.0)\n",
    "\n",
    "        # Augment\n",
    "        df_shifted = pd.DataFrame(shift_list, columns=X_aug.columns)\n",
    "        s_labels = pd.Series(label_list, name='target')\n",
    "        \n",
    "        X_aug = pd.concat([X_aug, df_shifted], ignore_index=True)\n",
    "        y_aug = pd.concat([y_aug, s_labels], ignore_index=True)\n",
    "        if use_weighted_fit:\n",
    "            sample_weights = np.concatenate([sample_weights, np.array(weight_list)])\n",
    "        else:\n",
    "            # Keep same weighting for original samples\n",
    "            sample_weights = np.ones(len(X_aug))\n",
    "\n",
    "        print(f\"  => Added {len(df_shifted)} new shifted samples; total = {len(X_aug)}\")\n",
    "\n",
    "    # Final training set: combine with X_val\n",
    "    X_final = pd.concat([X_aug, X_val], ignore_index=True)\n",
    "    y_final = pd.concat([y_aug, y_val], ignore_index=True)\n",
    "\n",
    "    final_weights = None\n",
    "    if use_weighted_fit:\n",
    "        # For simplicity, assume new samples from X_val have weight=1\n",
    "        w_val = np.ones(len(X_val))\n",
    "        final_weights = np.concatenate([sample_weights, w_val])\n",
    "    \n",
    "    # Downsample to final_train_size\n",
    "    if final_train_size is not None and final_train_size < len(X_final):\n",
    "        indices = rng.choice(len(X_final), size=final_train_size, replace=False)\n",
    "        X_final = X_final.iloc[indices].reset_index(drop=True)\n",
    "        y_final = y_final.iloc[indices].reset_index(drop=True)\n",
    "        if final_weights is not None:\n",
    "            final_weights = final_weights[indices]\n",
    "\n",
    "    # Final fit\n",
    "    if use_weighted_fit:\n",
    "        base_model.fit(X_final, y_final, sample_weight=final_weights)\n",
    "    else:\n",
    "        base_model.fit(X_final, y_final)\n",
    "\n",
    "    return base_model, X_final, y_final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Demo of Mechanistic Boosting on Shifted Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_mechanistic_robust_boosting(folder: str = \"data_folder\", n_rounds: int = 1):\n",
    "    \"\"\"\n",
    "    Demonstrates the Mechanistic-Interpretability-Guided Robust Boosting \n",
    "    approach on 'original.csv' and evaluates it on the shifted CSV files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : str, optional\n",
    "        The folder containing 'original.csv' and 'shifted_*.csv'.\n",
    "    n_rounds : int, optional\n",
    "        How many augmentation+retrain rounds to run.\n",
    "    \"\"\"\n",
    "    # 1) Load training data\n",
    "    df_orig = pd.read_csv(os.path.join(folder, \"original.csv\"))\n",
    "    X_train = df_orig.drop('target', axis=1)\n",
    "    y_train = df_orig['target']\n",
    "    \n",
    "    # 2) Baseline GBC for comparison\n",
    "    gbc_baseline = GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        max_features='log2',\n",
    "        min_samples_leaf=13,\n",
    "        n_estimators=100,\n",
    "        subsample=0.7\n",
    "    )\n",
    "    gbc_baseline.fit(X_train, y_train)\n",
    "    \n",
    "    # 3) Mechanistic interpretability-based boosting\n",
    "    gbc_mi, X_aug, y_aug = mech_interp_boosting(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        model=None,\n",
    "        base_shift_factor=0.2,\n",
    "        n_rounds=n_rounds,\n",
    "        min_improvement=0.001,\n",
    "        noise_scale=0.01,\n",
    "        n_features_to_shift= 4\n",
    "    )\n",
    "    \n",
    "    test_files = [f for f in os.listdir(folder) if f.startswith(\"shifted_\")]\n",
    "    print(f\"\\n=== Evaluate Baseline GBC vs. MI-Guided GBC (n_rounds={n_rounds}) on Shifted Data ===\\n\")\n",
    "    \n",
    "    for test_file in test_files:\n",
    "        df_test = pd.read_csv(os.path.join(folder, test_file))\n",
    "        X_test = df_test.drop('target', axis=1)\n",
    "        y_test = df_test['target']\n",
    "        \n",
    "        y_pred_b = gbc_baseline.predict(X_test)\n",
    "        y_proba_b = gbc_baseline.predict_proba(X_test)[:, 1]\n",
    "        acc_b = accuracy_score(y_test, y_pred_b)\n",
    "        f1_b = f1_score(y_test, y_pred_b)\n",
    "        auc_b = roc_auc_score(y_test, y_proba_b)\n",
    "        \n",
    "        \n",
    "        y_pred_m = gbc_mi.predict(X_test)\n",
    "        y_proba_m = gbc_mi.predict_proba(X_test)[:, 1]\n",
    "        acc_m = accuracy_score(y_test, y_pred_m)\n",
    "        f1_m = f1_score(y_test, y_pred_m)\n",
    "        auc_m = roc_auc_score(y_test, y_proba_m)\n",
    "        \n",
    "        print(f\"Shifted file: {test_file}\")\n",
    "        print(f\"  Baseline GBC => Acc: {acc_b:.3f}, F1: {f1_b:.3f}, AUC: {auc_b:.3f}\")\n",
    "        print(f\"  MI-Guided GBC => Acc: {acc_m:.3f}, F1: {f1_m:.3f}, AUC: {auc_m:.3f}\")\n",
    "        print(\"---------------------------------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo_mechanistic_robust_boosting(\"data_folder\", n_rounds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline_gb(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.Series,\n",
    "    final_train_size: int = None,\n",
    "    random_state: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a standard GradientBoosting on exactly 'final_train_size' points \n",
    "    (if provided). If final_train_size < len(X_train), downsample first.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    \n",
    "    if final_train_size is not None and final_train_size < len(X_train):\n",
    "        indices = rng.choice(len(X_train), size=final_train_size, replace=False)\n",
    "        X_train = X_train.iloc[indices].reset_index(drop=True)\n",
    "        y_train = y_train.iloc[indices].reset_index(drop=True)\n",
    "    \n",
    "    model = GradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        max_features='log2',\n",
    "        min_samples_leaf=13,\n",
    "        n_estimators=100,\n",
    "        subsample=0.7,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7. Compare All Models: Original, Adversarial, Mechanistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_performance(folder: str = \"data_folder\"):\n",
    "    \"\"\"\n",
    "    Compare performance between:\n",
    "      - Original Gradient Boosting\n",
    "      - Adversarially Trained Gradient Boosting\n",
    "      - Mechanistically-Interpreted (MI) Model\n",
    "      \n",
    "    Plots side-by-side bar charts of Accuracy, F1, AUC for each shifted dataset.\n",
    "    \"\"\"\n",
    "    df_orig = pd.read_csv(os.path.join(folder, \"original.csv\"))\n",
    "    X_train = df_orig.drop('target', axis=1)\n",
    "    y_train = df_orig['target']\n",
    "\n",
    "    final_size = len(X_train)\n",
    "    gbc_original = train_baseline_gb(X_train, y_train, final_train_size=final_size)\n",
    "\n",
    "    \n",
    "    gbc_adversarial, X_adv, y_adv = adversarial_training_gbc(\n",
    "    X_train, y_train,\n",
    "    epsilon=0.1,\n",
    "    max_rounds=3,\n",
    "    fraction_to_perturb=0.5,\n",
    "    final_train_size=final_size\n",
    ")\n",
    "\n",
    "\n",
    "    gbc_mech, X_mi, y_mi = mech_interp_boosting(\n",
    "    X_train, y_train,\n",
    "    base_shift_factor=0.1,\n",
    "    n_rounds=3,\n",
    "    fraction_to_shift=0.7,\n",
    "    use_weighted_fit=True,\n",
    "    final_train_size=final_size\n",
    ")\n",
    "\n",
    "\n",
    "    # Evaluate these three models on all shifted CSVs\n",
    "    test_files = [f for f in os.listdir(folder) if f.startswith(\"shifted_\")]\n",
    "    results = []\n",
    "    model_dict = {\n",
    "        \"OriginalGB\": gbc_original,\n",
    "        \"AdversarialGB\": gbc_adversarial,\n",
    "        \"MechInterpGB\": gbc_mech\n",
    "    }\n",
    "\n",
    "    for model_name, model_obj in model_dict.items():\n",
    "        for test_file in test_files:\n",
    "            df_test = pd.read_csv(os.path.join(folder, test_file))\n",
    "            X_test = df_test.drop('target', axis=1)\n",
    "            y_test = df_test['target']\n",
    "\n",
    "            y_pred = model_obj.predict(X_test)\n",
    "            y_pred_proba = model_obj.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            f1_ = f1_score(y_test, y_pred)\n",
    "            auc_ = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "            results.append({\n",
    "                \"Model\": model_name,\n",
    "                \"ShiftedFile\": test_file,\n",
    "                \"Accuracy\": acc,\n",
    "                \"F1\": f1_,\n",
    "                \"AUC\": auc_\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    metrics_to_plot = [\"Accuracy\", \"F1\", \"AUC\"]\n",
    "\n",
    "    fig1, axes1 = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        sns.barplot(data=df_results, x=\"ShiftedFile\", y=metric, hue=\"Model\", ax=axes1[idx])\n",
    "        axes1[idx].set_title(f\"{metric} Comparison\")\n",
    "        axes1[idx].set_xticklabels(axes1[idx].get_xticklabels(), rotation=45)\n",
    "        axes1[idx].set_ylim(0, 1.05)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    fig2, axes2 = plt.subplots(1, 3, figsize=(20, 5))\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_to_plot):\n",
    "        pivot_data = df_results.pivot(index='ShiftedFile', \n",
    "                                    columns='Model', \n",
    "                                    values=metric)\n",
    "        \n",
    "        relative_improvement = 100 * (pivot_data - pivot_data['OriginalGB'].values.reshape(-1,1)) / pivot_data['OriginalGB'].values.reshape(-1,1)\n",
    "        \n",
    "        sns.barplot(data=relative_improvement[['AdversarialGB', 'MechInterpGB']], ax=axes2[idx])\n",
    "        \n",
    "        axes2[idx].set_title(f'Relative {metric} Improvement (%)')\n",
    "        axes2[idx].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "        axes2[idx].set_xticklabels(axes2[idx].get_xticklabels(), rotation=45)\n",
    "        axes2[idx].set_ylabel('Improvement %')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare_models_performance(\"data_folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE CELL TO RUN THEM ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # 1) Generate data for n_features\n",
    "create_shifted_datasets(n_features=4, output_folder=\"data\", base_n_samples=1000, cov_scale=3.5, mean_shift_scale=2.5)\n",
    "\n",
    "#  # 2) Visualize shifts\n",
    "visualize_feature_shifts(\"data\", features_to_plot=(0,1))\n",
    "\n",
    "#  # 3) Evaluate baseline models\n",
    "# #evaluate_models_on_shifts(\"data\")\n",
    "\n",
    "#  # 4) Compare adv vs normal\n",
    "# #compare_adversarial_training(\"data\")\n",
    "\n",
    "#  # 5) Mechanistic robust boosting\n",
    "# #demo_mechanistic_robust_boosting(\"data\", n_rounds=1)\n",
    "\n",
    "#  # 6) Compare all\n",
    "compare_models_performance(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tune_mechinterp_hparams(\n",
    "#     folder: str = \"data_folder\",\n",
    "#     base_shift_candidates = [0.05, 0.1, 0.2],\n",
    "#     fraction_candidates = [0.3, 0.5, 0.7],\n",
    "#     n_rounds: int = 3,\n",
    "#     final_train_size: int = None,\n",
    "#     random_state: int = 42\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     1. Load the original dataset from `folder`.\n",
    "#     2. Train baseline GB + Adversarial GB for reference.\n",
    "#     3. For each (base_shift_factor, fraction_to_shift) in the grid:\n",
    "#        - Train a MechInterp model.\n",
    "#        - Evaluate on the same shifted CSVs.\n",
    "#     4. Compare performance + Return a table of all results + Identify best combo.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     folder : str\n",
    "#         Folder containing original.csv and shifted_*.csv.\n",
    "#     base_shift_candidates : list\n",
    "#         Values to try for `base_shift_factor`.\n",
    "#     fraction_candidates : list\n",
    "#         Values to try for `fraction_to_shift`.\n",
    "#     n_rounds : int\n",
    "#         Rounds of MechInterp training.\n",
    "#     final_train_size : int or None\n",
    "#         If not None, downsample final training set to keep dataset size fair.\n",
    "#     random_state : int\n",
    "#         For reproducibility.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         A DataFrame summarizing all runs (Model, base_shift, fraction, ShiftFile, Accuracy, F1, AUC).\n",
    "#     (float, float)\n",
    "#         The best (base_shift_factor, fraction_to_shift) combo (based on chosen metric).\n",
    "#     \"\"\"\n",
    "#     # 1) Load original => train data\n",
    "#     df_orig = pd.read_csv(os.path.join(folder, \"original.csv\"))\n",
    "#     X_train = df_orig.drop('target', axis=1)\n",
    "#     y_train = df_orig['target']\n",
    "#     if final_train_size is None:\n",
    "#         final_train_size = len(X_train)  # default to full training size\n",
    "\n",
    "#     # 2) Train baseline\n",
    "#     gbc_baseline = train_baseline_gb(\n",
    "#         X_train, y_train, \n",
    "#         final_train_size=final_train_size, \n",
    "#         random_state=random_state\n",
    "#     )\n",
    "\n",
    "#     # 2b) Train adversarial\n",
    "#     gbc_adv, X_adv, y_adv = adversarial_training_gbc(\n",
    "#         X_train, y_train,\n",
    "#         epsilon=0.1,\n",
    "#         max_rounds=3,\n",
    "#         fraction_to_perturb=0.5,\n",
    "#         final_train_size=final_train_size,\n",
    "#         random_state=random_state\n",
    "#     )\n",
    "\n",
    "#     # We'll evaluate on each shifted file\n",
    "#     test_files = [f for f in os.listdir(folder) if f.startswith(\"shifted_\")]\n",
    "    \n",
    "#     # Collect all results in a list of dicts\n",
    "#     all_results = []\n",
    "    \n",
    "#     # Evaluate Baseline + Adversarial once here\n",
    "#     model_dict = {\n",
    "#         \"OriginalGB\": gbc_baseline,\n",
    "#         \"AdversarialGB\": gbc_adv\n",
    "#     }\n",
    "    \n",
    "#     for model_name, model_obj in model_dict.items():\n",
    "#         for test_file in test_files:\n",
    "#             df_test = pd.read_csv(os.path.join(folder, test_file))\n",
    "#             X_test = df_test.drop('target', axis=1)\n",
    "#             y_test = df_test['target']\n",
    "            \n",
    "#             y_pred = model_obj.predict(X_test)\n",
    "#             y_proba = model_obj.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "#             all_results.append({\n",
    "#                 \"Model\": model_name,\n",
    "#                 \"BaseShiftFactor\": None,\n",
    "#                 \"FractionShift\": None,\n",
    "#                 \"ShiftedFile\": test_file,\n",
    "#                 \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "#                 \"F1\": f1_score(y_test, y_pred),\n",
    "#                 \"AUC\": roc_auc_score(y_test, y_proba)\n",
    "#             })\n",
    "\n",
    "#     # 3) For each combo of base_shift_factor, fraction_to_shift => train MechInterp\n",
    "#     for base_shift in base_shift_candidates:\n",
    "#         for fraction_shift in fraction_candidates:\n",
    "#             model_name_combo = f\"MechInterp_s{base_shift}_f{fraction_shift}\"\n",
    "            \n",
    "#             # Train MechInterp\n",
    "#             gbc_mech, X_mech, y_mech = mech_interp_boosting(\n",
    "#                 X_train, y_train,\n",
    "#                 base_model=None,\n",
    "#                 base_shift_factor=base_shift,\n",
    "#                 n_rounds=n_rounds,\n",
    "#                 fraction_to_shift=fraction_shift,\n",
    "#                 min_improvement=0.001,\n",
    "#                 noise_scale=0.01,\n",
    "#                 n_features_to_shift=2,  # or your choice\n",
    "#                 final_train_size=final_train_size,\n",
    "#                 use_weighted_fit=True,\n",
    "#                 random_state=random_state\n",
    "#             )\n",
    "            \n",
    "#             # Evaluate on each shifted file\n",
    "#             for test_file in test_files:\n",
    "#                 df_test = pd.read_csv(os.path.join(folder, test_file))\n",
    "#                 X_test = df_test.drop('target', axis=1)\n",
    "#                 y_test = df_test['target']\n",
    "                \n",
    "#                 y_pred = gbc_mech.predict(X_test)\n",
    "#                 y_proba = gbc_mech.predict_proba(X_test)[:, 1]\n",
    "                \n",
    "#                 all_results.append({\n",
    "#                     \"Model\": model_name_combo,\n",
    "#                     \"BaseShiftFactor\": base_shift,\n",
    "#                     \"FractionShift\": fraction_shift,\n",
    "#                     \"ShiftedFile\": test_file,\n",
    "#                     \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "#                     \"F1\": f1_score(y_test, y_pred),\n",
    "#                     \"AUC\": roc_auc_score(y_test, y_proba)\n",
    "#                 })\n",
    "\n",
    "#     df_all = pd.DataFrame(all_results)\n",
    "\n",
    "#     # 4) Identify best combo:\n",
    "#     # Let's pick \"best\" as highest average AUC across all shifted files\n",
    "#     # (You can change to F1 or average of all metrics.)\n",
    "#     # Filter only rows with Model starting in \"MechInterp_\"\n",
    "#     df_mech = df_all[df_all[\"Model\"].str.startswith(\"MechInterp_s\")]\n",
    "    \n",
    "#     # Group by (BaseShiftFactor, FractionShift), average the AUC\n",
    "#     grouped = df_mech.groupby([\"BaseShiftFactor\", \"FractionShift\"])[\"AUC\"].mean().reset_index()\n",
    "#     best_row = grouped.loc[grouped[\"AUC\"].idxmax()]  # row with highest mean AUC\n",
    "#     best_base_shift = best_row[\"BaseShiftFactor\"]\n",
    "#     best_fraction = best_row[\"FractionShift\"]\n",
    "#     best_auc = best_row[\"AUC\"]\n",
    "    \n",
    "#     print(\"\\n======== MechInterp Hyperparam Tuning Results ========\")\n",
    "#     print(df_mech.groupby([\"BaseShiftFactor\", \"FractionShift\"])[[\"Accuracy\",\"F1\",\"AUC\"]].mean())\n",
    "#     print(\"======================================================\\n\")\n",
    "#     print(f\"Best Combination (by avg AUC): base_shift={best_base_shift}, fraction={best_fraction}, AUC={best_auc:.3f}\")\n",
    "    \n",
    "#     return df_all, (best_base_shift, best_fraction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) Ensure data_folder has original.csv + shifted_*.csv\n",
    "# df_results, (best_bs, best_fr) = tune_mechinterp_hparams(\n",
    "#     folder=\"data\",\n",
    "#     base_shift_candidates=[0.05, 0.1, 0.2],\n",
    "#     fraction_candidates=[0.3, 0.5, 0.7],\n",
    "#     n_rounds=3,\n",
    "#     final_train_size=None  # or a specific integer\n",
    "# )\n",
    "\n",
    "# print(\"\\nFull Results:\\n\", df_results.head(20))\n",
    "\n",
    "# print(f\"\\nBest MechInterp Hyperparameters found: base_shift_factor={best_bs}, fraction_to_shift={best_fr}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
