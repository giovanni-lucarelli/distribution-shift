{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Huge \\blue{\\textbf{Distribution shift \\qquad}} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\text{Analysis of different models over shifted datasets}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\text{Imports \\& settings}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, roc_auc_score, accuracy_score, \n",
    "    f1_score, roc_curve\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from pygam import s, te, f, LogisticGAM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from src.data_generation import *\n",
    "from src.analysis import compare_adversarial_training, ModelEvaluator\n",
    "from src.utils import *\n",
    "from src.plotting import visualize_feature_shifts\n",
    "\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "\n",
    "# Parameter definition\n",
    "\n",
    "num_samples = 1000\n",
    "num_features = 3\n",
    "\n",
    "# degree of the polinomio for the attribute relationship\n",
    "degree = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y\n",
       "1    523\n",
       "0    477\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random multivariate\n",
    "\n",
    "mean_train = [0.90920214, 0.81962487, 0.88819135]\n",
    "\n",
    "covariance_train = np.array([[0.726318, 0.20240102, 0.52472545],\n",
    "                             [0.20240102, 0.11392557, 0.0264108],\n",
    "                             [0.52472545, 0.0264108, 1.05107627]])\n",
    "\n",
    "# build the features sample\n",
    "sample_train = build_multivariate_sample(num_samples, mean_train, covariance_train)\n",
    "df_train = pd.DataFrame(sample_train, columns=[f'X{i+1}' for i in range(num_features)])\n",
    "\n",
    "# build target variable y\n",
    "# random coefficients (otherwise remove coef from build_poly_target and will be randomly generated)\n",
    "coef = [-0.8061577012389105, -0.3621987584904036, -0.16057091147074054, 0.4803476403769713, -0.10624889645240687, \n",
    "        0.3182084398201366, 0.6789895126695962, -0.791324832566177, 0.531479159887424, 0.49115959567000167]\n",
    "\n",
    "y_train, coef_train = build_poly_target(sample_train, degree, coef)\n",
    "df_train['Y'] = y_train\n",
    "\n",
    "# check for balance\n",
    "df_train['Y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Sets: Shifted Distribution Mixtures\n",
    "\n",
    "To be as general as possible, we consider statistical mixtures and study the presumed progressive degradation in performance for increasingly pure mixtures towards the test distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shifted random multivariate\n",
    "mean_shift = attributes_quantile(df_train, 0.05)\n",
    "\n",
    "covariance_shift = [[ 0.16309729,  0.19325742, -0.12621892],\n",
    "                    [ 0.19325742,  0.25197638, -0.13972381],\n",
    "                    [-0.12621892, -0.13972381,  0.19160666]]\n",
    "\n",
    "# Initialize an empty dictionary to store the dataframes\n",
    "df_dict = {}\n",
    "\n",
    "# Iterate over mix_prob values\n",
    "for mix_prob in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "    # Generate mixture sample\n",
    "    sample_mix = build_mixture_sample(num_samples, mean_train, covariance_train, mean_shift, covariance_shift, mix_prob=mix_prob)\n",
    "\n",
    "    # Create a DataFrame for the features\n",
    "    df_mix = pd.DataFrame(sample_mix, columns=[f'X{i+1}' for i in range(num_features)])\n",
    "\n",
    "    # Build the target variable y\n",
    "    y_mix, coef_mix = build_poly_target(sample_mix, degree, coefficients=coef_train)\n",
    "    df_mix['Y'] = y_mix\n",
    "\n",
    "    # Store the DataFrame in the dictionary\n",
    "    df_dict[mix_prob] = df_mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: the 0.0 is a sample from the distribution that generated the training set. Since `build_mixture_sample` function do the dample each time, the 0.0 sample can be used as test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder\n",
    "folder_name = os.path.join('data')\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "for mix_prob, df in df_dict.items():\n",
    "    df.to_csv(os.path.join(folder_name, f'mix_{mix_prob}.csv'), index=False)\n",
    "file_name = 'Parameters.txt'\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "df_train.to_csv(os.path.join(folder_name, 'train.csv'), index=False)\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "  f.write('Polinomial coefficients\\n')\n",
    "  f.write(f'{coef_train}\\n')\n",
    "  f.write('Mean train\\n')\n",
    "  f.write(f'{mean_train}\\n')\n",
    "  f.write('Covariance train\\n')\n",
    "  f.write(f'{covariance_train}\\n')\n",
    "  f.write('Mean shift\\n')\n",
    "  f.write(f'{mean_shift}\\n')\n",
    "  f.write('Covariance shift\\n')\n",
    "  f.write(f'{covariance_shift}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " For higher dimensional data (n > 2), we can either:\n",
    "\n",
    " - Visualize a pairwise scatter matrix (e.g., `sns.pairplot`) for a subset of features.\n",
    "\n",
    " - Or just visualize a specified pair of features for a quick glimpse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_feature_shifts(df_dict=df_dict, features_to_plot= ['X1', 'X2', 'X3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load train data\n",
    "\n",
    "# X_train = df_train.drop('Y', axis=1)\n",
    "# y_train = df_train['Y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgam_params = {\n",
    "#     \"terms\": s(0) + s(1) + s(2) + te(0, 1) + te(0, 2) + te(1, 2),\n",
    "#     \"max_iter\": 100\n",
    "# }\n",
    "\n",
    "# lgam_model = LogisticGAM(**lgam_params).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgam_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Decision Tree Parameters\n",
    "\n",
    "# dtc_params = {\n",
    "#     \"max_depth\": 4,\n",
    "#     \"min_samples_leaf\": 13\n",
    "# }\n",
    "\n",
    "# dtc_model = DecisionTreeClassifier(**dtc_params)\n",
    "# dtc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gradient Boosting Parameters\n",
    "# gbc_params = {\n",
    "#     \"learning_rate\": 0.05,\n",
    "#     \"max_depth\": 4,\n",
    "#     \"max_features\": 'log2',\n",
    "#     \"min_samples_leaf\": 13,\n",
    "#     \"n_estimators\": 100,\n",
    "#     \"subsample\": 0.7\n",
    "# }\n",
    "\n",
    "# gbc_model = GradientBoostingClassifier(**gbc_params)\n",
    "# gbc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Parameters\n",
    "# xgb_params = {\n",
    "#     \"learning_rate\":0.025,\n",
    "#     \"max_depth\":5,\n",
    "#     \"n_estimators\":100,\n",
    "#     \"subsample\":0.7\n",
    "# }\n",
    "\n",
    "# xgb_model = xgb.XGBClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 4. Model Evaluation After the Distribution Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the models to evaluate\n",
    "\n",
    "# models = {\n",
    "#     \"LogisticGAM\" : lgam_model,\n",
    "#     \"DecisionTreeClassifier\" : dtc_model,\n",
    "#     \"GradientBoostingClassifier\" : gbc_model,\n",
    "#     # \"XGBoost\" : xgb_model\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming df_dict is a dictionary with keys from 0.1 to 1.0\n",
    "# test_datasets = [(key, df.drop('Y', axis=1), df['Y']) for key, df in df_dict.items() if 0.0 <= key <= 1.0]\n",
    "\n",
    "# evaluator = ModelEvaluator(models, test_datasets)\n",
    "# evaluator.evaluate_models(show_metrics=True)\n",
    "# evaluator.plot_roc_curves()\n",
    "# evaluator.plot_roc_curves_per_dataset()\n",
    "# evaluator.plot_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 5. Adversarial Training for GradientBoosting (General n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Compare Normal vs. Adversarial Training on Shifted Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, info in models.items():\n",
    "#   compare_adversarial_training(\n",
    "#     DATA_FOLDER, \n",
    "#     model_class=info[\"class\"],\n",
    "#     model_params=info[\"params\"],\n",
    "#   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 6. Mechanistic-Interpretability-Guided Robust Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from src.robust_training.mechanistic import MechanisticTrainer\n",
    "try:\n",
    "    from pygam import LogisticGAM\n",
    "    PYGAM_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYGAM_AVAILABLE = False\n",
    "\n",
    "\n",
    "def run_mechanistic_robust_training_and_eval(\n",
    "    folder: str = \"dat\",\n",
    "    target: str = 'Y',\n",
    "    n_rounds: int = 2,\n",
    "    model_type: str = 'gbc',  # Options: 'gbc', 'tree', 'gam'\n",
    "    base_shift_factor: float = 0.1,\n",
    "    fraction_to_shift: float = 0.7,\n",
    "    final_train_size: Optional[int] = None,\n",
    "    random_state: int = 42,\n",
    "    noise_scale: float = 0.001,\n",
    "    n_grad_steps: int = 1,\n",
    "    top_k: int = 5\n",
    ") -> Tuple[BaseEstimator, BaseEstimator]:\n",
    "    \"\"\"\n",
    "    Trains both a baseline model and a robust model using MechanisticTrainer,\n",
    "    then evaluates both models on all shifted test files in the specified folder.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    folder : str\n",
    "        Directory containing 'mix_0.0.csv' for training and 'mix_<n>.csv' for testing.\n",
    "    target : str\n",
    "        Name of the target variable in the datasets.\n",
    "    n_rounds : int\n",
    "        Number of augmentation rounds for MechanisticTrainer.\n",
    "    model_type : str\n",
    "        Type of model to use for robust training. Options: 'gbc', 'tree', 'gam'.\n",
    "    base_shift_factor : float\n",
    "        Magnitude by which to shift selected features during augmentation.\n",
    "    fraction_to_shift : float\n",
    "        Fraction of the dataset to select for augmentation each round.\n",
    "    final_train_size : int or None\n",
    "        If specified, downsample the final training set to this size.\n",
    "    random_state : int\n",
    "        Seed for reproducibility.\n",
    "    noise_scale : float\n",
    "        Standard deviation of Gaussian noise added to augmented samples.\n",
    "    n_grad_steps : int\n",
    "        Number of gradient-based steps per sample during augmentation.\n",
    "    top_k : int\n",
    "        Number of top features (by gradient magnitude) to shift per sample.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    baseline_model : BaseEstimator\n",
    "        The baseline model trained on the original data.\n",
    "    robust_model : BaseEstimator\n",
    "        The robustly trained model using MechanisticTrainer.\n",
    "    \"\"\"\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 1) Load original training data from \"mix_0.0.csv\"\n",
    "    # ----------------------------------------------------------------------\n",
    "    train_file = os.path.join(folder, \"train.csv\")\n",
    "    if not os.path.exists(train_file):\n",
    "        raise FileNotFoundError(f\"Training file '{train_file}' not found in folder '{folder}'.\")\n",
    "\n",
    "    df_orig = pd.read_csv(train_file)\n",
    "    if target not in df_orig.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in '{train_file}'.\")\n",
    "\n",
    "    X_train = df_orig.drop(columns=[target])\n",
    "    y_train = df_orig[target]\n",
    "\n",
    "    print(f\"Loaded training data from '{train_file}' with shape = {X_train.shape}\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 2) Train Baseline Model\n",
    "    #    Ensure baseline uses the same model_type for fair comparison.\n",
    "    # ----------------------------------------------------------------------\n",
    "    print(\"\\n=== Training Baseline Model ===\")\n",
    "    if model_type == 'gbc':\n",
    "        baseline_model = GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=3,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif model_type == 'tree':\n",
    "        baseline_model = DecisionTreeClassifier(\n",
    "            max_depth=5,\n",
    "            random_state=random_state\n",
    "        )\n",
    "    elif model_type == 'gam':\n",
    "        if not PYGAM_AVAILABLE:\n",
    "            raise ImportError(\"pyGAM is not installed. Install it via `pip install pygam` or choose another model type.\")\n",
    "        baseline_model = LogisticGAM( verbose=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model_type '{model_type}'. Choose from ['gbc', 'tree', 'gam'].\")\n",
    "\n",
    "    baseline_model.fit(X_train, y_train)\n",
    "    print(\"Baseline model trained.\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 3) Train Mechanistic-Interpretability-Guided Robust Model\n",
    "    # ----------------------------------------------------------------------\n",
    "    print(\"\\n=== Training Mechanistic-Interpretability-Guided Robust Model ===\")\n",
    "    trainer = MechanisticTrainer(\n",
    "        model_type=model_type,         # 'gbc', 'tree', 'gam'\n",
    "        base_shift_factor=base_shift_factor,\n",
    "        n_rounds=n_rounds,\n",
    "        subset_size_fraction=fraction_to_shift,\n",
    "        n_grad_steps=n_grad_steps,\n",
    "        top_k=top_k,\n",
    "        random_state=random_state,\n",
    "        noise_scale=noise_scale,\n",
    "       \n",
    "        val_fraction=0.1,               # Fraction for validation split\n",
    "        eps = 0.1\n",
    "    )\n",
    "\n",
    "    # Optionally, initialize the model externally if needed\n",
    "    # e.g., trainer.model = some_pretrained_model\n",
    "\n",
    "    # Fit the robust model\n",
    "    trainer.fit(X_train, y_train)\n",
    "    robust_model = trainer.model\n",
    "    print(\"Robust model trained.\")\n",
    "\n",
    "    # If final_train_size is specified, downsample & refit\n",
    "    if final_train_size is not None and final_train_size < len(trainer.X_final):\n",
    "        rng = np.random.RandomState(random_state)\n",
    "        idx_down = rng.choice(len(trainer.X_final), size=final_train_size, replace=False)\n",
    "        X_down = trainer.X_final.iloc[idx_down].reset_index(drop=True)\n",
    "        y_down = trainer.y_final.iloc[idx_down].reset_index(drop=True)\n",
    "        robust_model.fit(X_down, y_down)\n",
    "        print(f\"Final training set downsampled to {final_train_size} samples.\")\n",
    "\n",
    "    # ----------------------------------------------------------------------\n",
    "    # 4) Evaluate on all shifted test files: \"mix_<n>.csv\"\n",
    "    # ----------------------------------------------------------------------\n",
    "    test_files = [\n",
    "        f for f in os.listdir(folder)\n",
    "        if f.startswith(\"mix_\") and f.endswith(\".csv\") and f #!= \"mix_0.0.csv\"\n",
    "    ]\n",
    "\n",
    "    if not test_files:\n",
    "        print(f\"\\nNo shifted test files found in '{folder}' for evaluation.\")\n",
    "        return baseline_model, robust_model\n",
    "\n",
    "    print(\"\\n=== Evaluation on Shifted Test Files ===\")\n",
    "    for test_file in sorted(test_files):\n",
    "        test_path = os.path.join(folder, test_file)\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        if target not in df_test.columns:\n",
    "            print(f\"Skipping '{test_file}': missing target '{target}'.\")\n",
    "            continue\n",
    "\n",
    "        X_test = df_test.drop(columns=[target])\n",
    "        y_test = df_test[target]\n",
    "\n",
    "        # Evaluate Baseline Model\n",
    "        y_pred_b = baseline_model.predict(X_test)\n",
    "        if hasattr(baseline_model, \"predict_proba\"):\n",
    "            y_proba_b = baseline_model.predict_proba(X_test)[:, 1]\n",
    "            try:\n",
    "                auc_b = roc_auc_score(y_test, y_proba_b)\n",
    "            except ValueError:\n",
    "                auc_b = \"N/A (only one class present)\"\n",
    "        else:\n",
    "            y_proba_b = None\n",
    "            auc_b = \"N/A\"\n",
    "\n",
    "        acc_b = accuracy_score(y_test, y_pred_b)\n",
    "        f1_b = f1_score(y_test, y_pred_b, average='weighted')  # Use 'weighted' for multiclass\n",
    "\n",
    "        # Evaluate Robust Model\n",
    "        y_pred_r = robust_model.predict(X_test)\n",
    "        if hasattr(robust_model, \"predict_proba\"):\n",
    "            y_proba_r = robust_model.predict_proba(X_test)[:, 1]\n",
    "            try:\n",
    "                auc_r = roc_auc_score(y_test, y_proba_r)\n",
    "            except ValueError:\n",
    "                auc_r = \"N/A (only one class present)\"\n",
    "        else:\n",
    "            y_proba_r = None\n",
    "            auc_r = \"N/A\"\n",
    "\n",
    "        acc_r = accuracy_score(y_test, y_pred_r)\n",
    "        f1_r = f1_score(y_test, y_pred_r, average='weighted')  # Use 'weighted' for multiclass\n",
    "\n",
    "        print(f\"\\nTest File: {test_file}\")\n",
    "        print(f\"  Baseline Model => Accuracy: {acc_b:.3f}, F1 Score: {f1_b:.3f}, AUC: {auc_b}\")\n",
    "        print(f\"  Robust Model   => Accuracy: {acc_r:.3f}, F1 Score: {f1_r:.3f}, AUC: {auc_r}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return baseline_model, robust_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded training data from 'data\\train.csv' with shape = (1000, 3)\n",
      "\n",
      "=== Training Baseline Model ===\n",
      "Baseline model trained.\n",
      "\n",
      "=== Training Mechanistic-Interpretability-Guided Robust Model ===\n",
      "[MechanisticTrainer] Initial fit on training set.\n",
      "[MechanisticTrainer] Augmentation Round 1/1\n"
     ]
    }
   ],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "TARGET_COLUMN = 'Y'\n",
    "\n",
    "# Run the robust training and evaluation\n",
    "baseline_model, robust_model = run_mechanistic_robust_training_and_eval(\n",
    "    folder=DATA_FOLDER,\n",
    "    target=TARGET_COLUMN,\n",
    "    n_rounds=1,\n",
    "    model_type='tree',          # Options: 'gbc', 'tree', 'gam'\n",
    "    base_shift_factor=100,\n",
    "    fraction_to_shift=0.9,\n",
    "    final_train_size=1000,     # Keep the original size\n",
    "    random_state=42,\n",
    "    noise_scale=0.0001,\n",
    "    n_grad_steps=5,\n",
    "    top_k=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_baseline_gb(\n",
    "#     X_train: pd.DataFrame,\n",
    "#     y_train: pd.Series,\n",
    "#     final_train_size: int = None,\n",
    "#     random_state: int = 42\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Train a standard GradientBoosting on exactly 'final_train_size' points \n",
    "#     (if provided). If final_train_size < len(X_train), downsample first.\n",
    "#     \"\"\"\n",
    "#     import numpy as np\n",
    "#     from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "#     rng = np.random.RandomState(random_state)\n",
    "    \n",
    "#     if final_train_size is not None and final_train_size < len(X_train):\n",
    "#         indices = rng.choice(len(X_train), size=final_train_size, replace=False)\n",
    "#         X_train = X_train.iloc[indices].reset_index(drop=True)\n",
    "#         y_train = y_train.iloc[indices].reset_index(drop=True)\n",
    "    \n",
    "#     model = GradientBoostingClassifier(\n",
    "#         learning_rate=0.05,\n",
    "#         max_depth=4,\n",
    "#         max_features='log2',\n",
    "#         min_samples_leaf=13,\n",
    "#         n_estimators=100,\n",
    "#         subsample=0.7,\n",
    "#         random_state=random_state\n",
    "#     )\n",
    "#     model.fit(X_train, y_train)\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 7. Compare All Models: Original, Adversarial, Mechanistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_models_performance(folder: str = \"data\", target = 'Y'):\n",
    "#     \"\"\"\n",
    "#     Compare performance between:\n",
    "#       - Original Gradient Boosting\n",
    "#       - Adversarially Trained Gradient Boosting\n",
    "#       - Mechanistically-Interpreted (MI) Model\n",
    "      \n",
    "#     Plots side-by-side bar charts of Accuracy, F1, AUC for each shifted dataset.\n",
    "#     \"\"\"\n",
    "#     df_orig = pd.read_csv(os.path.join(folder, \"mix_0.0.csv\"))\n",
    "#     X_train = df_orig.drop(target, axis=1)\n",
    "#     y_train = df_orig[target]\n",
    "\n",
    "#     final_size = len(X_train)\n",
    "#     gbc_original = train_baseline_gb(X_train, y_train, final_train_size=final_size)\n",
    "    \n",
    "#     gbc_adversarial, X_adv, y_adv = adversarial_training(\n",
    "#         X_train, y_train,\n",
    "#         epsilon=0.1,\n",
    "#         max_rounds=3,\n",
    "#         fraction_to_perturb=0.5,\n",
    "#         final_train_size=final_size\n",
    "#     )\n",
    "    \n",
    "#     gbc_mech, X_mi, y_mi = mech_interp_boosting(\n",
    "#         X_train, y_train,\n",
    "#         base_shift_factor=0.1,\n",
    "#         n_rounds=3,\n",
    "#         fraction_to_shift=0.7,\n",
    "#         use_weighted_fit=True,\n",
    "#         final_train_size=final_size\n",
    "#     )\n",
    "\n",
    "#     # Evaluate these three models on all shifted CSVs\n",
    "#     test_files = [f for f in os.listdir(folder) if f.startswith(\"mix_\")]\n",
    "#     test_files = sorted([f for f in os.listdir(folder) if f.startswith(\"mix_\")], \n",
    "#                key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "#     results = []\n",
    "#     model_dict = {\n",
    "#         \"OriginalGB\": gbc_original,\n",
    "#         \"AdversarialGB\": gbc_adversarial,\n",
    "#         \"MechInterpGB\": gbc_mech\n",
    "#     }\n",
    "\n",
    "#     for model_name, model_obj in model_dict.items():\n",
    "#         for test_file in sorted(test_files):\n",
    "#             df_test = pd.read_csv(os.path.join(folder, sorted(test_files)[test_files.index(test_file)]))\n",
    "#             X_test = df_test[X_train.columns]\n",
    "#             y_test = df_test[target]\n",
    "\n",
    "#             y_pred = model_obj.predict(X_test)\n",
    "#             y_pred_proba = model_obj.predict_proba(X_test)[:, 1]\n",
    "\n",
    "#             acc = accuracy_score(y_test, y_pred)\n",
    "#             f1_ = f1_score(y_test, y_pred)\n",
    "#             auc_ = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "#             results.append({\n",
    "#                 \"Model\": model_name,\n",
    "#                 \"ShiftedFile\": test_file,\n",
    "#                 \"Accuracy\": acc,\n",
    "#                 \"F1\": f1_,\n",
    "#                 \"AUC\": auc_\n",
    "#             })\n",
    "\n",
    "#     df_results = pd.DataFrame(results)\n",
    "#     metrics_to_plot = [\"Accuracy\", \"F1\", \"AUC\"]\n",
    "    \n",
    "#     # Updated plotting code with fixed legends\n",
    "#     fig1, axes1 = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    \n",
    "#     for idx, metric in enumerate(metrics_to_plot):\n",
    "#         sns.barplot(\n",
    "#             data=df_results, \n",
    "#             x=\"ShiftedFile\", \n",
    "#             y=metric, \n",
    "#             hue=\"Model\",\n",
    "#             ax=axes1[idx]\n",
    "#         )\n",
    "#         axes1[idx].set_title(f\"{metric} Comparison\")\n",
    "#         #axes1[idx].set_xticklabels(\n",
    "#         #    axes1[idx].get_xticklabels(), \n",
    "#         #    rotation=45, \n",
    "#         #    ha='right'\n",
    "#         #)\n",
    "#         #axes1[idx].set_ylim(0, 1.05)\n",
    "#         axes1[idx].legend(title=\"Models\")\n",
    "        \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     fig2, axes2 = plt.subplots(3, 1, figsize=(10, 15))\n",
    "    \n",
    "#     for idx, metric in enumerate(metrics_to_plot):\n",
    "#         pivot_data = df_results.pivot(\n",
    "#             index='ShiftedFile', \n",
    "#             columns='Model', \n",
    "#             values=metric\n",
    "#         )\n",
    "        \n",
    "#         rel_improvement = 100 * (\n",
    "#             pivot_data - pivot_data['OriginalGB'].values.reshape(-1,1)\n",
    "#         ) / pivot_data['OriginalGB'].values.reshape(-1,1)\n",
    "        \n",
    "#         # Explicitly set labels for legend\n",
    "#         rel_improvement_plot = rel_improvement[['AdversarialGB', 'MechInterpGB']].reset_index()\n",
    "#         rel_improvement_plot = pd.melt(\n",
    "#             rel_improvement_plot, \n",
    "#             id_vars=['ShiftedFile'],\n",
    "#             var_name='Model',\n",
    "#             value_name='Improvement'\n",
    "#         )\n",
    "        \n",
    "#         sns.barplot(\n",
    "#             data=rel_improvement_plot,\n",
    "#             x='ShiftedFile',\n",
    "#             y='Improvement',\n",
    "#             hue='Model',\n",
    "#             ax=axes2[idx]\n",
    "#         )\n",
    "        \n",
    "#         axes2[idx].set_title(f'Relative {metric} Improvement (%)')\n",
    "#         axes2[idx].axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "#         #axes2[idx].set_xticklabels(\n",
    "#         #    axes2[idx].get_xticklabels(), \n",
    "#         #    rotation=45,\n",
    "#         #    ha='right'\n",
    "#         #)\n",
    "#         axes2[idx].set_ylabel('Improvement %')\n",
    "#         axes2[idx].legend(title=\"Models\")\n",
    "        \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_models_performance(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONE CELL TO RUN THEM ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Generate data for n_features\n",
    "# create_shifted_datasets(n_features=4, output_folder=\"data\", base_n_samples=1000, cov_scale=3.5, mean_shift_scale=2.5)\n",
    "\n",
    "# 2) Visualize shifts\n",
    "# visualize_feature_shifts(DATA_FOLDER, features_to_plot=['X1', 'X2', 'X3'])\n",
    "\n",
    "# 3) Evaluate baseline models\n",
    "# evaluate_models_on_shifts(DATA_FOLDER)\n",
    "\n",
    "# 4) Compare adv vs normal\n",
    "# compare_adversarial_training(DATA_FOLDER)\n",
    "\n",
    "# 5) Mechanistic robust boosting\n",
    "# demo_mechanistic_robust_boosting(DATA_FOLDER, n_rounds=2)\n",
    "\n",
    "# 6) Compare all\n",
    "# compare_models_performance(DATA_FOLDER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tune_mechinterp_hparams(\n",
    "#     folder: str = \"data\",\n",
    "#     base_shift_candidates = [0.05, 0.1, 0.2],\n",
    "#     fraction_candidates = [0.3, 0.5, 0.7],\n",
    "#     target = 'Y',\n",
    "#     n_rounds: int = 3,\n",
    "#     final_train_size: int = None,\n",
    "#     random_state: int = 42\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     1. Load the original dataset from `folder`.\n",
    "#     2. Train baseline GB + Adversarial GB for reference.\n",
    "#     3. For each (base_shift_factor, fraction_to_shift) in the grid:\n",
    "#        - Train a MechInterp model.\n",
    "#        - Evaluate on the same shifted CSVs.\n",
    "#     4. Compare performance + Return a table of all results + Identify best combo.\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     folder : str\n",
    "#         Folder containing mix_*.csv.\n",
    "#     base_shift_candidates : list\n",
    "#         Values to try for `base_shift_factor`.\n",
    "#     fraction_candidates : list\n",
    "#         Values to try for `fraction_to_shift`.\n",
    "#     n_rounds : int\n",
    "#         Rounds of MechInterp training.\n",
    "#     final_train_size : int or None\n",
    "#         If not None, downsample final training set to keep dataset size fair.\n",
    "#     random_state : int\n",
    "#         For reproducibility.\n",
    "#     Returns\n",
    "#     -------\n",
    "#     pd.DataFrame\n",
    "#         A DataFrame summarizing all runs (Model, base_shift, fraction, ShiftFile, Accuracy, F1, AUC).\n",
    "#     (float, float)\n",
    "#         The best (base_shift_factor, fraction_to_shift) combo (based on chosen metric).\n",
    "#     \"\"\"\n",
    "#     # 1) Load original => train data\n",
    "#     df_orig = pd.read_csv(os.path.join(folder, \"mix_0.0.csv\"))\n",
    "#     X_train = df_orig.drop(target, axis=1)\n",
    "#     y_train = df_orig[target]\n",
    "#     if final_train_size is None:\n",
    "#         final_train_size = len(X_train)  # default to full training size\n",
    "#     # 2) Train baseline\n",
    "#     gbc_baseline = train_baseline_gb(\n",
    "#         X_train, y_train, \n",
    "#         final_train_size=final_train_size, \n",
    "#         random_state=random_state\n",
    "#     )\n",
    "#     # 2b) Train adversarial\n",
    "#     gbc_adv, X_adv, y_adv = adversarial_training_gbc(\n",
    "#         X_train, y_train,\n",
    "#         epsilon=0.1,\n",
    "#         max_rounds=3,\n",
    "#         fraction_to_perturb=0.5,\n",
    "#         final_train_size=final_train_size,\n",
    "#         random_state=random_state\n",
    "#     )\n",
    "#     # We'll evaluate on each shifted file\n",
    "#     test_files = [f for f in os.listdir(folder) if f.startswith(\"shifted_\")]\n",
    "  \n",
    "#     # Collect all results in a list of dicts\n",
    "#     all_results = []\n",
    "  \n",
    "#     # Evaluate Baseline + Adversarial once here\n",
    "#     model_dict = {\n",
    "#         \"OriginalGB\": gbc_baseline,\n",
    "#         \"AdversarialGB\": gbc_adv\n",
    "#     }\n",
    "  \n",
    "#     for model_name, model_obj in model_dict.items():\n",
    "#         for test_file in test_files:\n",
    "#             df_test = pd.read_csv(os.path.join(folder, test_file))\n",
    "#             X_test = df_test[X_train.columns]\n",
    "#             y_test = df_test[target]\n",
    "          \n",
    "#             y_pred = model_obj.predict(X_test)\n",
    "#             y_proba = model_obj.predict_proba(X_test)[:, 1]\n",
    "          \n",
    "#             all_results.append({\n",
    "#                 \"Model\": model_name,\n",
    "#                 \"BaseShiftFactor\": None,\n",
    "#                 \"FractionShift\": None,\n",
    "#                 \"ShiftedFile\": test_file,\n",
    "#                 \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "#                 \"F1\": f1_score(y_test, y_pred),\n",
    "#                 \"AUC\": roc_auc_score(y_test, y_proba)\n",
    "#             })\n",
    "#     # 3) For each combo of base_shift_factor, fraction_to_shift => train MechInterp\n",
    "#     for base_shift in base_shift_candidates:\n",
    "#         for fraction_shift in fraction_candidates:\n",
    "#             model_name_combo = f\"MechInterp_s{base_shift}_f{fraction_shift}\"\n",
    "          \n",
    "#             # Train MechInterp\n",
    "#             gbc_mech, X_mech, y_mech = mech_interp_boosting(\n",
    "#                 X_train, y_train,\n",
    "#                 base_model=None,\n",
    "#                 base_shift_factor=base_shift,\n",
    "#                 n_rounds=n_rounds,\n",
    "#                 fraction_to_shift=fraction_shift,\n",
    "#                 min_improvement=0.001,\n",
    "#                 noise_scale=0.01,\n",
    "#                 n_features_to_shift=2,  # or your choice\n",
    "#                 final_train_size=final_train_size,\n",
    "#                 use_weighted_fit=True,\n",
    "#                 random_state=random_state\n",
    "#             )\n",
    "          \n",
    "#             # Evaluate on each shifted file\n",
    "#             for test_file in sorted(test_files):\n",
    "#                 df_test = pd.read_csv(os.path.join(folder, test_file))\n",
    "#                 X_test = df_test[X_train.columns]\n",
    "#                 y_test = df_test[target]\n",
    "              \n",
    "#                 y_pred = gbc_mech.predict(X_test)\n",
    "#                 y_proba = gbc_mech.predict_proba(X_test)[:, 1]\n",
    "              \n",
    "#                 all_results.append({\n",
    "#                     \"Model\": model_name_combo,\n",
    "#                     \"BaseShiftFactor\": base_shift,\n",
    "#                     \"FractionShift\": fraction_shift,\n",
    "#                     \"ShiftedFile\": test_file,\n",
    "#                     \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "#                     \"F1\": f1_score(y_test, y_pred),\n",
    "#                     \"AUC\": roc_auc_score(y_test, y_proba)\n",
    "#                 })\n",
    "#     df_all = pd.DataFrame(all_results)\n",
    "#     # 4) Identify best combo:\n",
    "#     # Let's pick \"best\" as highest average AUC across all shifted files\n",
    "#     # (You can change to F1 or average of all metrics.)\n",
    "#     # Filter only rows with Model starting in \"MechInterp_\"\n",
    "#     df_mech = df_all[df_all[\"Model\"].str.startswith(\"MechInterp_s\")]\n",
    "  \n",
    "#     # Group by (BaseShiftFactor, FractionShift), average the AUC\n",
    "#     grouped = df_mech.groupby([\"BaseShiftFactor\", \"FractionShift\"])[\"AUC\"].mean().reset_index()\n",
    "#     best_row = grouped.loc[grouped[\"AUC\"].idxmax()]  # row with highest mean AUC\n",
    "#     best_base_shift = best_row[\"BaseShiftFactor\"]\n",
    "#     best_fraction = best_row[\"FractionShift\"]\n",
    "#     best_auc = best_row[\"AUC\"]\n",
    "  \n",
    "#     print(\"\\n======== MechInterp Hyperparam Tuning Results ========\")\n",
    "#     print(df_mech.groupby([\"BaseShiftFactor\", \"FractionShift\"])[[\"Accuracy\",\"F1\",\"AUC\"]].mean())\n",
    "#     print(\"======================================================\\n\")\n",
    "#     print(f\"Best Combination (by avg AUC): base_shift={best_base_shift}, fraction={best_fraction}, AUC={best_auc:.3f}\")\n",
    "  \n",
    "#     return df_all, (best_base_shift, best_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1) Ensure data_folder has train.csv + mix_*.csv\n",
    "# df_results, (best_bs, best_fr) = tune_mechinterp_hparams(\n",
    "#     folder=\"data\",\n",
    "#     base_shift_candidates=[0.05, 0.1, 0.2],\n",
    "#     fraction_candidates=[0.3, 0.5, 0.7],\n",
    "#     n_rounds=3,\n",
    "#     final_train_size=None  # or a specific integer\n",
    "# )\n",
    "# print(\"\\nFull Results:\\n\", df_results.head(20))\n",
    "# print(f\"\\nBest MechInterp Hyperparameters found: base_shift_factor={best_bs}, fraction_to_shift={best_fr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
