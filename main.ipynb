{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Huge \\blue{\\textbf{Simple Covariate Shift \\qquad}} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve #, classification_report, roc_auc_score, accuracy_score, f1_score, \n",
    "    \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from pygam import s, te, f, LogisticGAM\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from src.data_generation import *\n",
    "from src.analysis import ModelEvaluator\n",
    "from src.utils import *\n",
    "from src.plotting import visualize_feature_shifts\n",
    "from src.grid_search import *\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import Logit\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "GRID_SEARCH = False\n",
    "PLOT = False\n",
    "GEN_DATA = True\n",
    "OVERFIT = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "\n",
    "# Parameter definition\n",
    "\n",
    "num_samples = 10000\n",
    "num_features = 3\n",
    "\n",
    "# degree of the polinomio for the attribute relationship\n",
    "degree = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GEN_DATA:\n",
    "    # random multivariate\n",
    "\n",
    "    mean_train = [0.90920214, 0.81962487, 0.88819135]\n",
    "\n",
    "    covariance_train = np.array([[0.726318, 0.20240102, 0.52472545],\n",
    "                                [0.20240102, 0.11392557, 0.0264108],\n",
    "                                [0.52472545, 0.0264108, 1.05107627]])\n",
    "\n",
    "    # build the features sample\n",
    "    sample_train = build_multivariate_sample(num_samples, mean_train, covariance_train)\n",
    "    sample_train\n",
    "\n",
    "    df_train = pd.DataFrame(sample_train, columns=[f'X{i+1}' for i in range(num_features)])\n",
    "\n",
    "    # build target variable y\n",
    "    # random coefficients (otherwise remove coef from build_poly_target and will be randomly generated)\n",
    "    coef = [-0.8061577012389105, -0.3621987584904036, -0.16057091147074054, 0.4803476403769713, -0.10624889645240687, \n",
    "            0.3182084398201366, 0.6789895126695962, -0.791324832566177, 0.531479159887424, 0.49115959567000167]\n",
    "\n",
    "    y_train, z_train, coef_train = build_poly_target(sample_train, degree, coef)\n",
    "    df_train['Y'] = y_train\n",
    "    df_train['Z'] = z_train\n",
    "\n",
    "    # check for balance\n",
    "    df_train['Y'].value_counts()\n",
    "\n",
    "    ir = max(df_train['Y'].value_counts()) / min(df_train['Y'].value_counts())\n",
    "    ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head() if GEN_DATA else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Sets: Shifted Distribution Mixtures\n",
    "\n",
    "To be as general as possible, we consider statistical mixtures and study the presumed progressive degradation in performance for increasingly pure mixtures towards the test distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GEN_DATA:\n",
    "    # shifted random multivariate\n",
    "    mean_shift = attributes_quantile(df_train, 0.05)\n",
    "\n",
    "    covariance_shift = [[ 0.16309729,  0.19325742, -0.12621892],\n",
    "                        [ 0.19325742,  0.25197638, -0.13972381],\n",
    "                        [-0.12621892, -0.13972381,  0.19160666]]\n",
    "\n",
    "    # Initialize an empty dictionary to store the dataframes\n",
    "    df_dict = {}\n",
    "\n",
    "    # Iterate over mix_prob values\n",
    "    for mix_prob in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "        # Generate mixture sample\n",
    "        sample_mix = build_mixture_sample(num_samples, mean_train, covariance_train, mean_shift, covariance_shift, mix_prob=mix_prob)\n",
    "\n",
    "        # Create a DataFrame for the features\n",
    "        df_mix = pd.DataFrame(sample_mix, columns=[f'X{i+1}' for i in range(num_features)])\n",
    "\n",
    "        # Build the target variable y\n",
    "        y_mix, z_mix, coef_mix = build_poly_target(sample_mix, degree, coefficients=coef_train)\n",
    "        df_mix['Y'] = y_mix\n",
    "        df_mix['Z'] = z_mix\n",
    "\n",
    "        # Store the DataFrame in the dictionary\n",
    "        df_dict[mix_prob] = df_mix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ir = {}\n",
    "\n",
    "for mprob in df_dict.keys():\n",
    "    ir[mprob] = max(df_dict[mprob]['Y'].value_counts()) / min(df_dict[mprob]['Y'].value_counts())\n",
    "\n",
    "ir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: the 0.0 is a sample from the distribution that generated the training set. Since `build_mixture_sample` function do the sample each time, the 0.0 sample can be used as test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GEN_DATA:\n",
    "    # Create a folder\n",
    "    os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "\n",
    "    for mix_prob, df in df_dict.items():\n",
    "        df.to_csv(os.path.join(DATA_FOLDER, f'mix_{mix_prob}.csv'), index=False)\n",
    "    file_name = 'Parameters.txt'\n",
    "    file_path = os.path.join(DATA_FOLDER, file_name)\n",
    "    df_train.to_csv(os.path.join(DATA_FOLDER, 'train.csv'), index=False)\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write('Polinomial coefficients\\n')\n",
    "        f.write(f'{coef_train}\\n')\n",
    "        f.write('Mean train\\n')\n",
    "        f.write(f'{mean_train}\\n')\n",
    "        f.write('Covariance train\\n')\n",
    "        f.write(f'{covariance_train}\\n')\n",
    "        f.write('Mean shift\\n')\n",
    "        f.write(f'{mean_shift}\\n')\n",
    "        f.write('Covariance shift\\n')\n",
    "        f.write(f'{covariance_shift}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GEN_DATA:\n",
    "    # Read data\n",
    "    df_train = pd.read_csv(os.path.join(DATA_FOLDER, 'train.csv'))\n",
    "    X_train = df_train.drop(columns=['Y', 'Z'])\n",
    "    y_train = df_train['Y']\n",
    "    z_train = df_train['Z']\n",
    "    df_dict = {}\n",
    "    for mix_prob in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "        df_dict[mix_prob] = pd.read_csv(os.path.join(DATA_FOLDER, f'mix_{mix_prob}.csv'))\n",
    "    \n",
    "    with open(os.path.join(DATA_FOLDER, \"Parameters.txt\"), 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        # Line with coefficients (second line)\n",
    "        coef_line = lines[1].strip()\n",
    "        # Convert string representation of list to actual list\n",
    "        coef_train = eval(coef_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head() if not GEN_DATA else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Shifted Set - Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "    # Plot X1 vs X2\n",
    "    sns.scatterplot(ax=axes[0], x=df_train['X1'], y=df_train['X2'], label='Train Data')\n",
    "    sns.scatterplot(ax=axes[0], x=df_dict[1.0]['X1'], y=df_dict[1.0]['X2'], label='Shifted Data')\n",
    "    axes[0].scatter(mean_shift['X1'], mean_shift['X2'], color='red', s=100, label='Mean Shift')\n",
    "    axes[0].set_title('X1 vs X2')\n",
    "    axes[0].set_xlabel('X1')\n",
    "    axes[0].set_ylabel('X2')\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Plot X1 vs X3\n",
    "    sns.scatterplot(ax=axes[1], x=df_train['X1'], y=df_train['X3'], label='Train Data')\n",
    "    sns.scatterplot(ax=axes[1], x=df_dict[1.0]['X1'], y=df_dict[1.0]['X3'], label='Shifted Data')\n",
    "    axes[1].scatter(mean_shift['X1'], mean_shift['X3'], color='red', s=100, label='Mean Shift')\n",
    "    axes[1].set_title('X1 vs X3')\n",
    "    axes[1].set_xlabel('X1')\n",
    "    axes[1].set_ylabel('X3')\n",
    "    axes[1].legend()\n",
    "\n",
    "    # Plot X2 vs X3\n",
    "    sns.scatterplot(ax=axes[2], x=df_train['X2'], y=df_train['X3'], label='Train Data')\n",
    "    sns.scatterplot(ax=axes[2], x=df_dict[1.0]['X2'], y=df_dict[1.0]['X3'], label='Shifted Data')\n",
    "    axes[2].scatter(mean_shift['X2'], mean_shift['X3'], color='red', s=100, label='Mean Shift')\n",
    "    axes[2].set_title('X2 vs X3')\n",
    "    axes[2].set_xlabel('X2')\n",
    "    axes[2].set_ylabel('X3')\n",
    "    axes[2].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(DATA_FOLDER, 'scatter_plots.pdf'))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixture Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    mixprob = 0.5\n",
    "    # Plot marginal distribution of X1\n",
    "    sns.histplot(df_train['X1'], kde=True, ax=axes[0])\n",
    "    sns.histplot(df_dict[mixprob]['X1'], kde=True, ax=axes[0], color='orange')\n",
    "    axes[0].set_title('Marginal Distribution of X1')\n",
    "    axes[0].set_xlabel('X1')\n",
    "    axes[0].set_ylabel('Density')\n",
    "    axes[0].legend(['Train Data', 'Shifted Data'])\n",
    "\n",
    "    # Plot marginal distribution of X2\n",
    "    sns.histplot(df_train['X2'], kde=True, ax=axes[1])\n",
    "    sns.histplot(df_dict[mixprob]['X2'], kde=True, ax=axes[1], color='orange')\n",
    "    axes[1].set_title('Marginal Distribution of X2')\n",
    "    axes[1].set_xlabel('X2')\n",
    "    axes[1].set_ylabel('Density')\n",
    "    axes[1].legend(['Train Data', 'Shifted Data'])\n",
    "\n",
    "    # Plot marginal distribution of X3\n",
    "    sns.histplot(df_train['X3'], kde=True, ax=axes[2])\n",
    "    sns.histplot(df_dict[mixprob]['X3'], kde=True, ax=axes[2], color='orange')\n",
    "    axes[2].set_title('Marginal Distribution of X3')\n",
    "    axes[2].set_xlabel('X3')\n",
    "    axes[2].set_ylabel('Density')\n",
    "    axes[2].legend(['Train Data', 'Shifted Data'])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join('slides', 'assets', f'marginal_plots{mixprob}.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    # small_df_dict = {k: df_dict[k] for k in [0.0, 1.0]}\n",
    "    visualize_feature_shifts(df_dict=df_dict, features_to_plot= ['X1', 'X2', 'X3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    sns.pairplot(df_train, vars=['X1', 'X2', 'X3'], hue='Y')\n",
    "    plt.savefig(os.path.join('slides', 'assets', 'pairplot.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    \n",
    "    sns.pairplot(df_dict[1.0], vars=['X1', 'X2', 'X3'], hue='Y')\n",
    "    plt.savefig(os.path.join('slides', 'assets', 'pairplotshift.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "\n",
    "X_train = df_train.drop(['Y','Z'], axis=1)\n",
    "y_train = df_train['Y']\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant to the independent variables matrix\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "logit_model = sm.Logit(y_train, X_train_sm)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Print the summary of the model\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_model = LogisticRegression(\n",
    "    penalty = None,         # No Regularization                     [default on R]\n",
    "    solver = 'newton-cg',   # optimizer, simil to Newton-Raphson,   [default on R]\n",
    "    fit_intercept = True,   # include intercept in the model        [default on R]\n",
    "    max_iter = 25           # Max number of iterations              [default on R]\n",
    ")\n",
    "\n",
    "lreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Random Forest\n",
    "rf_grid = {\n",
    "    'n_estimators'      : [100],#[100, 125, 150],\n",
    "    'criterion'         : ['gini'],#['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth'         : [5],#[3, 4, 5],\n",
    "    'min_samples_split' : [5],#[4, 5, 6],\n",
    "    'min_samples_leaf'  : [1],#, 4, 8],\n",
    "    'random_state'      : [0]\n",
    "}\n",
    "\n",
    "if GRID_SEARCH:\n",
    "   rfc_model = grid_search_cv(RandomForestClassifier(), rf_grid, X_train, y_train, n_jobs=-1)\n",
    "else:\n",
    "   rfc_model = RandomForestClassifier(**best_params[\"RandomForestClassifier\"])\n",
    "   rfc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for Gradient Boosting\n",
    "gbc_grid = {\n",
    "    'n_estimators'          : [100, 125, 150],\n",
    "    'learning_rate'         : [0.025, 0.01, 0.0075],\n",
    "    'max_depth'             : [3, 4, 5],\n",
    "    'min_samples_leaf'      : [6, 8, 10],\n",
    "    'subsample'             : [0.3, 0.4, 0.5],\n",
    "    'max_features'          : [None]#, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "if GRID_SEARCH:\n",
    "    gbc_model = grid_search_cv(GradientBoostingClassifier(), gbc_grid, X_train, y_train, n_jobs=-1)\n",
    "else:\n",
    "    gbc_model = GradientBoostingClassifier(**best_params[\"GradientBoostingClassifier\"])\n",
    "    gbc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Parameters\n",
    "xgb_grid = {\n",
    "    'n_estimators'      : [25, 50, 75],\n",
    "    'learning_rate'     : [0.1, 0.3, 0.5],\n",
    "    'max_depth'         : [2, 4, 6],\n",
    "    'min_child_weight'  : [1, 2, 3],\n",
    "    'subsample'         : [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree'  : [0.8, 1.0],\n",
    "    'reg_alpha'         : [1], #[0, 1, 5],\n",
    "    'reg_lambda'        : [1], #[1, 5, 10],\n",
    "    'gamma'             : [5], #[0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "best_params[\"XGBoost\"] = {\n",
    "        'n_estimators': None,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': None,\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': None,\n",
    "        'reg_alpha': None,\n",
    "        'reg_lambda': None,\n",
    "        'gamma': 5\n",
    "    }\n",
    "\n",
    "if GRID_SEARCH:\n",
    "    xgb_model = grid_search_cv_xgb(xgb_grid, X_train, y_train, n_jobs=-1)\n",
    "else:\n",
    "    xgb_model = xgb.XGBClassifier(**best_params[\"XGBoost\"])\n",
    "    xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 4. Model Evaluation on Shifted Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to evaluate\n",
    "\n",
    "models = {\n",
    "    #\"DecisionTreeClassifier\"        : dtc_model,\n",
    "    \"RandomForestClassifier\"        : rfc_model,\n",
    "    \"GradientBoostingClassifier\"    : gbc_model,\n",
    "    \"XGBoost\"                       : xgb_model,\n",
    "    \"LogisticRegression\"            : lreg_model\n",
    "}\n",
    "\n",
    "# Assuming df_dict is a dictionary with keys from 0.1 to 1.0\n",
    "test_datasets = [(key, df.drop(['Y','Z'], axis=1), df['Y']) for key, df in df_dict.items() if 0.0 <= key <= 1.0]\n",
    "\n",
    "evaluator = ModelEvaluator(models, test_datasets)\n",
    "evaluator.evaluate_models(show_metrics = False)\n",
    "evaluator.plot_roc_curves()\n",
    "#evaluator.plot_roc_curves_per_dataset()\n",
    "evaluator.plot_auc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_df = {}\n",
    "\n",
    "N_EXP = 50\n",
    "\n",
    "#if GEN_DATA:\n",
    "for i in range(N_EXP):\n",
    "    # shifted random multivariate\n",
    "    mean_shift = attributes_quantile(df_train, 0.05)\n",
    "\n",
    "    covariance_shift = random_cov(num_features, -0.5, 0.5)\n",
    "\n",
    "    # Initialize an empty dictionary to store the dataframes\n",
    "    experiment_df[i] = {}\n",
    "\n",
    "    # Iterate over mix_prob values\n",
    "    for mix_prob in [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "        # Generate mixture sample\n",
    "        sample_mix = build_mixture_sample(num_samples, mean_train, covariance_train, mean_shift, covariance_shift, mix_prob=mix_prob)\n",
    "\n",
    "        # Create a DataFrame for the features\n",
    "        df_mix = pd.DataFrame(sample_mix, columns=[f'X{i+1}' for i in range(num_features)])\n",
    "\n",
    "        # Build the target variable y\n",
    "        y_mix, z_mix, coef_mix = build_poly_target(sample_mix, degree, coefficients=coef_train)\n",
    "        df_mix['Y'] = y_mix\n",
    "        df_mix['Z'] = z_mix\n",
    "\n",
    "        # Store the DataFrame in the dictionary\n",
    "        experiment_df[i][mix_prob] = df_mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Gradient Boosting Classifier\"    : gbc_model,\n",
    "    \"Random Forest Classifier\"        : rfc_model,\n",
    "    \"XGBoost\"                         : xgb_model,\n",
    "    \"Logistic Regression\"             : lreg_model\n",
    "    }\n",
    "\n",
    "results = {}\n",
    "\n",
    "for idx, test_data in experiment_df.items(): # datasets = {idx : { sh_idx : sh_df }}\n",
    "    test_datasets = [(key, df.drop(['Y','Z'], axis=1), df['Y']) for key, df in test_data.items() if 0.0 <= key <= 1.0]\n",
    "    evaluator = ModelEvaluator(models, test_datasets)\n",
    "    results[idx] = evaluator.evaluate_models(show_metrics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other_results = {}\n",
    "\n",
    "# for idx, result in results.items():\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     for model_name, datasets in result.items():\n",
    "#         if model_name not in other_results:\n",
    "#            other_results[model_name] = []\n",
    "#         dataset_names = [metrics[\"dataset_name\"] for metrics in datasets.values()]\n",
    "#         auc = [metrics[\"auc\"] for metrics in datasets.values()]\n",
    "#         plt.plot(dataset_names, auc, marker='o', label=model_name)\n",
    "\n",
    "#     plt.title(\"ROC AUC for Each Model on Different Test Sets\", fontsize=16)\n",
    "#     plt.xlabel(\"Test Set\", fontsize=14)\n",
    "#     plt.ylabel(\"AUC\", fontsize=14)\n",
    "#     plt.legend(loc=\"best\", fontsize=12)\n",
    "#     plt.grid(alpha=0.5)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = {}\n",
    "\n",
    "for idx, result in results.items():\n",
    "    for model_name, datasets in result.items():\n",
    "        # print(datasets.keys())\n",
    "        # print()\n",
    "        if model_name not in final_results:\n",
    "           final_results[model_name] = []\n",
    "        #dataset_names = [metrics[\"dataset_name\"] for metrics in datasets.values()]\n",
    "        auc = datasets[10][\"auc\"]\n",
    "        final_results[model_name].append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the final_results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(final_results)\n",
    "\n",
    "# Calculate the median AUC for each model\n",
    "median_auc = results_df.median().sort_values(ascending=False)\n",
    "\n",
    "# Sort the DataFrame by the median AUC values\n",
    "sorted_results_df = results_df[median_auc.index]\n",
    "\n",
    "# Plot the sorted results\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(data=sorted_results_df, palette=['lightblue', 'sandybrown', 'lightgreen', 'lightcoral'])\n",
    "#ax.set_ylim(0.2, 0.9)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_results = {}\n",
    "\n",
    "for idx, result in results.items():\n",
    "    for model_name, datasets in result.items():\n",
    "        if model_name not in mean_results:\n",
    "           mean_results[model_name] = []\n",
    "        # Get AUC values for all datasets (0 to 10)\n",
    "        #auc_values = \n",
    "        # Calculate mean AUC\n",
    "        mean_auc = np.mean([datasets[i][\"auc\"] for i in range(11)])\n",
    "        mean_results[model_name].append(mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the final_results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(mean_results)\n",
    "\n",
    "# Calculate the median AUC for each model\n",
    "median_auc = results_df.median().sort_values(ascending=False)\n",
    "\n",
    "# Sort the DataFrame by the median AUC values\n",
    "sorted_results_df = results_df[median_auc.index]\n",
    "\n",
    "# Plot the sorted results\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = sns.boxplot(data=sorted_results_df)\n",
    "#ax.set_ylim(0.2, 0.9)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
